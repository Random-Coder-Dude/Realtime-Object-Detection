{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Random-Coder-Dude/Realtime-Object-Detection/blob/main/limelight-detector-training-notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJVo_xMPf4LY"
      },
      "source": [
        "![TrainingNotebookLogo.png](https://downloads.limelightvision.io/content/TrainingNotebookLogo.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72xbzFQrPL5q"
      },
      "source": [
        "To train a neural object detector for Limelight, click the \"play\" button on each code block. Pay extra attention to any \"â—\" you see. By the end of this tutorial, you will have downloaded a .zip file containing your model and label files.\n",
        "\n",
        "See https://docs.limelightvision.io/docs/docs-limelight/pipeline-neural/training-your-own-detector for a more in-depth tutorial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05N8FeXHcQp3"
      },
      "source": [
        "# 1. Install The Object Detection Package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ypWGYdPlLRUN",
        "outputId": "198c0824-a491-44c8-e7a8-74453cd6a427",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'models' already exists and is not an empty directory.\n",
            "remote: Enumerating objects: 3055, done.\u001b[K\n",
            "remote: Counting objects: 100% (3055/3055), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1359/1359), done.\u001b[K\n",
            "remote: Total 1824 (delta 1223), reused 703 (delta 446), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (1824/1824), 10.05 MiB | 10.62 MiB/s, done.\n",
            "Resolving deltas: 100% (1223/1223), completed with 739 local objects.\n",
            "From https://github.com/tensorflow/models\n",
            " * branch            ad1f7b56943998864db8f5db0706950e93bb7d81 -> FETCH_HEAD\n",
            "HEAD is now at ad1f7b5 adjust folder path\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: protobuf==3.20.3 in ./.local/lib/python3.10/site-packages (3.20.3)\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "import os\n",
        "tmpModelPath ='/content/models'\n",
        "if os.path.exists(tmpModelPath) and os.path.isdir(tmpModelPath):\n",
        "  shutil.rmtree(tmpModelPath)\n",
        "\n",
        "MLENVIRONMENT=\"COLAB\"\n",
        "!git clone --depth 1 https://github.com/tensorflow/models\n",
        "!cd models && git fetch --depth 1 origin ad1f7b56943998864db8f5db0706950e93bb7d81 && git checkout ad1f7b56943998864db8f5db0706950e93bb7d81\n",
        "!pip install protobuf==3.20.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6QPmVBSlLTzM",
        "outputId": "65d2c1a6-09f6-47b3-b5c4-63c7b2fe0df1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.10.12 (main, Jan 17 2025, 14:35:34) [GCC 11.4.0]\n",
            "colab env setup\n",
            "/home/atharv/\n",
            "/home/atharv/models/research\n"
          ]
        }
      ],
      "source": [
        "# Environment Setup\n",
        "import os\n",
        "import sys\n",
        "import re\n",
        "\n",
        "print(sys.version)\n",
        "if(MLENVIRONMENT == \"COLAB\"):\n",
        "    print(\"colab env setup\")\n",
        "    os.environ[\"HOMEFOLDER\"] = \"/home/atharv/\"\n",
        "    HOMEFOLDER = '{HOMEFOLDER}'.format(**os.environ)\n",
        "    FINALOUTPUTFOLDER_DIRNAME = 'final_output'\n",
        "    FINALOUTPUTFOLDER = HOMEFOLDER+FINALOUTPUTFOLDER_DIRNAME\n",
        "    print(HOMEFOLDER)\n",
        "\n",
        "# Copy setup files into models/research folder\n",
        "!cd {HOMEFOLDER}models/research && pwd && protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "# Modify setup.py\n",
        "with open(HOMEFOLDER+'models/research/object_detection/packages/tf2/setup.py') as f:\n",
        "    s = f.read()\n",
        "\n",
        "with open(HOMEFOLDER+'models/research/setup.py', 'w') as f:\n",
        "    if(MLENVIRONMENT == \"COLAB\"):\n",
        "        s = re.sub('tf-models-official>=2.5.1','tf-models-official==2.15.0', s)\n",
        "        f.write(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "OLDnCkLLwLr6",
        "outputId": "36e2f340-40ca-4c51-ff63-817c9f2c2dab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Processing ./models/research\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25hRequirement already satisfied: Cython in ./.local/lib/python3.10/site-packages (from object-detection==0.1) (3.0.11)\n",
            "Requirement already satisfied: apache-beam in ./.local/lib/python3.10/site-packages (from object-detection==0.1) (2.62.0)\n",
            "Requirement already satisfied: avro-python3 in ./.local/lib/python3.10/site-packages (from object-detection==0.1) (1.10.2)\n",
            "Requirement already satisfied: contextlib2 in ./.local/lib/python3.10/site-packages (from object-detection==0.1) (21.6.0)\n",
            "Requirement already satisfied: keras in ./.local/lib/python3.10/site-packages (from object-detection==0.1) (2.15.0)\n",
            "Requirement already satisfied: lvis in ./.local/lib/python3.10/site-packages (from object-detection==0.1) (0.5.3)\n",
            "Requirement already satisfied: lxml in ./.local/lib/python3.10/site-packages (from object-detection==0.1) (5.3.0)\n",
            "Requirement already satisfied: matplotlib in ./.local/lib/python3.10/site-packages (from object-detection==0.1) (3.10.0)\n",
            "Requirement already satisfied: pandas in ./.local/lib/python3.10/site-packages (from object-detection==0.1) (2.2.3)\n",
            "Requirement already satisfied: pillow in /usr/lib/python3/dist-packages (from object-detection==0.1) (9.0.1)\n",
            "Requirement already satisfied: pycocotools in ./.local/lib/python3.10/site-packages (from object-detection==0.1) (2.0.8)\n",
            "Requirement already satisfied: pyparsing==2.4.7 in /usr/lib/python3/dist-packages (from object-detection==0.1) (2.4.7)\n",
            "Requirement already satisfied: sacrebleu<=2.2.0 in ./.local/lib/python3.10/site-packages (from object-detection==0.1) (2.2.0)\n",
            "Requirement already satisfied: scipy in ./.local/lib/python3.10/site-packages (from object-detection==0.1) (1.15.1)\n",
            "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from object-detection==0.1) (1.16.0)\n",
            "Requirement already satisfied: tensorflow_io in ./.local/lib/python3.10/site-packages (from object-detection==0.1) (0.37.1)\n",
            "Requirement already satisfied: tf-models-official==2.15.0 in ./.local/lib/python3.10/site-packages (from object-detection==0.1) (2.15.0)\n",
            "Requirement already satisfied: tf-slim in ./.local/lib/python3.10/site-packages (from object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: seqeval in ./.local/lib/python3.10/site-packages (from tf-models-official==2.15.0->object-detection==0.1) (1.2.2)\n",
            "Requirement already satisfied: tensorflow-model-optimization>=0.4.1 in ./.local/lib/python3.10/site-packages (from tf-models-official==2.15.0->object-detection==0.1) (0.8.0)\n",
            "Requirement already satisfied: tensorflow~=2.15.0 in ./.local/lib/python3.10/site-packages (from tf-models-official==2.15.0->object-detection==0.1) (2.15.0)\n",
            "Requirement already satisfied: immutabledict in ./.local/lib/python3.10/site-packages (from tf-models-official==2.15.0->object-detection==0.1) (4.2.1)\n",
            "Requirement already satisfied: tensorflow-text~=2.15.0 in ./.local/lib/python3.10/site-packages (from tf-models-official==2.15.0->object-detection==0.1) (2.15.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in ./.local/lib/python3.10/site-packages (from tf-models-official==2.15.0->object-detection==0.1) (0.16.1)\n",
            "Requirement already satisfied: tensorflow-datasets in ./.local/lib/python3.10/site-packages (from tf-models-official==2.15.0->object-detection==0.1) (4.9.7)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in ./.local/lib/python3.10/site-packages (from tf-models-official==2.15.0->object-detection==0.1) (2.160.0)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in ./.local/lib/python3.10/site-packages (from tf-models-official==2.15.0->object-detection==0.1) (1.6.17)\n",
            "Requirement already satisfied: py-cpuinfo>=3.3.0 in ./.local/lib/python3.10/site-packages (from tf-models-official==2.15.0->object-detection==0.1) (9.0.0)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in ./.local/lib/python3.10/site-packages (from tf-models-official==2.15.0->object-detection==0.1) (6.0.2)\n",
            "Requirement already satisfied: psutil>=5.4.3 in ./.local/lib/python3.10/site-packages (from tf-models-official==2.15.0->object-detection==0.1) (6.1.1)\n",
            "Requirement already satisfied: sentencepiece in ./.local/lib/python3.10/site-packages (from tf-models-official==2.15.0->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: oauth2client in ./.local/lib/python3.10/site-packages (from tf-models-official==2.15.0->object-detection==0.1) (4.1.3)\n",
            "Requirement already satisfied: numpy>=1.20 in ./.local/lib/python3.10/site-packages (from tf-models-official==2.15.0->object-detection==0.1) (1.26.4)\n",
            "Requirement already satisfied: opencv-python-headless in ./.local/lib/python3.10/site-packages (from tf-models-official==2.15.0->object-detection==0.1) (4.11.0.86)\n",
            "Requirement already satisfied: gin-config in ./.local/lib/python3.10/site-packages (from tf-models-official==2.15.0->object-detection==0.1) (0.5.0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in ./.local/lib/python3.10/site-packages (from pandas->object-detection==0.1) (2025.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in ./.local/lib/python3.10/site-packages (from pandas->object-detection==0.1) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->object-detection==0.1) (2022.1)\n",
            "Requirement already satisfied: regex in ./.local/lib/python3.10/site-packages (from sacrebleu<=2.2.0->object-detection==0.1) (2024.11.6)\n",
            "Requirement already satisfied: portalocker in ./.local/lib/python3.10/site-packages (from sacrebleu<=2.2.0->object-detection==0.1) (3.1.1)\n",
            "Requirement already satisfied: colorama in /usr/lib/python3/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (0.4.4)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in ./.local/lib/python3.10/site-packages (from sacrebleu<=2.2.0->object-detection==0.1) (0.9.0)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in ./.local/lib/python3.10/site-packages (from tf-slim->object-detection==0.1) (1.4.0)\n",
            "Requirement already satisfied: sortedcontainers>=2.4.0 in ./.local/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (2.4.0)\n",
            "Requirement already satisfied: httplib2<0.23.0,>=0.8 in /usr/lib/python3/dist-packages (from apache-beam->object-detection==0.1) (0.20.2)\n",
            "Requirement already satisfied: orjson<4,>=3.9.7 in ./.local/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (3.10.15)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in ./.local/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (1.4.2)\n",
            "Requirement already satisfied: pymongo<5.0.0,>=3.8.0 in ./.local/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (4.11)\n",
            "Requirement already satisfied: packaging>=22.0 in ./.local/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (24.2)\n",
            "Requirement already satisfied: jsonpickle<4.0.0,>=3.0.0 in ./.local/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (3.4.2)\n",
            "Requirement already satisfied: pyarrow-hotfix<1 in ./.local/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (0.6)\n",
            "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in ./.local/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (2.7.3)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in ./.local/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Requirement already satisfied: proto-plus<2,>=1.7.1 in ./.local/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (1.26.0)\n",
            "Requirement already satisfied: zstandard<1,>=0.18.0 in ./.local/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (0.23.0)\n",
            "Requirement already satisfied: cloudpickle~=2.2.1 in ./.local/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (2.2.1)\n",
            "Requirement already satisfied: redis<6,>=5.0.0 in ./.local/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (5.2.1)\n",
            "Requirement already satisfied: pyarrow<17.0.0,>=3.0.0 in ./.local/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (16.1.0)\n",
            "Requirement already satisfied: grpcio!=1.48.0,!=1.59.*,!=1.60.*,!=1.61.*,!=1.62.0,!=1.62.1,<1.66.0,<2,>=1.33.1 in ./.local/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (1.65.5)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in ./.local/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (4.23.0)\n",
            "Requirement already satisfied: protobuf!=4.0.*,!=4.21.*,!=4.22.0,!=4.23.*,!=4.24.*,<6.0.0.dev0,>=3.20.3 in ./.local/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (3.20.3)\n",
            "Requirement already satisfied: objsize<0.8.0,>=0.6.1 in ./.local/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (0.7.1)\n",
            "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in ./.local/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (0.3.1.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.24.0 in ./.local/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (2.32.3)\n",
            "Requirement already satisfied: fasteners<1.0,>=0.3 in ./.local/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (0.19)\n",
            "Requirement already satisfied: fastavro<2,>=0.23.6 in ./.local/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (1.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.0 in ./.local/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (4.12.2)\n",
            "Requirement already satisfied: cycler>=0.10.0 in ./.local/lib/python3.10/site-packages (from lvis->object-detection==0.1) (0.12.1)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in ./.local/lib/python3.10/site-packages (from lvis->object-detection==0.1) (4.11.0.86)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in ./.local/lib/python3.10/site-packages (from lvis->object-detection==0.1) (1.4.8)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in ./.local/lib/python3.10/site-packages (from matplotlib->object-detection==0.1) (4.55.8)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in ./.local/lib/python3.10/site-packages (from matplotlib->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.37.1 in ./.local/lib/python3.10/site-packages (from tensorflow_io->object-detection==0.1) (0.37.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in ./.local/lib/python3.10/site-packages (from google-api-python-client>=1.6.7->tf-models-official==2.15.0->object-detection==0.1) (4.1.1)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in ./.local/lib/python3.10/site-packages (from google-api-python-client>=1.6.7->tf-models-official==2.15.0->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in ./.local/lib/python3.10/site-packages (from google-api-python-client>=1.6.7->tf-models-official==2.15.0->object-detection==0.1) (2.38.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in ./.local/lib/python3.10/site-packages (from google-api-python-client>=1.6.7->tf-models-official==2.15.0->object-detection==0.1) (2.24.1)\n",
            "Requirement already satisfied: docopt in ./.local/lib/python3.10/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in ./.local/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object-detection==0.1) (0.22.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in ./.local/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object-detection==0.1) (25.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./.local/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object-detection==0.1) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in ./.local/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object-detection==0.1) (0.36.2)\n",
            "Requirement already satisfied: urllib3 in /usr/lib/python3/dist-packages (from kaggle>=1.3.9->tf-models-official==2.15.0->object-detection==0.1) (1.26.5)\n",
            "Requirement already satisfied: tqdm in ./.local/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official==2.15.0->object-detection==0.1) (4.67.1)\n",
            "Requirement already satisfied: bleach in ./.local/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official==2.15.0->object-detection==0.1) (6.2.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in ./.local/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official==2.15.0->object-detection==0.1) (2025.1.31)\n",
            "Requirement already satisfied: python-slugify in ./.local/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official==2.15.0->object-detection==0.1) (8.0.4)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in ./.local/lib/python3.10/site-packages (from pymongo<5.0.0,>=3.8.0->apache-beam->object-detection==0.1) (2.7.0)\n",
            "Requirement already satisfied: async-timeout>=4.0.3 in ./.local/lib/python3.10/site-packages (from redis<6,>=5.0.0->apache-beam->object-detection==0.1) (5.0.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.4.1)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in ./.local/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (1.14.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in ./.local/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (18.1.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in ./.local/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (2.15.0)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in ./.local/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./.local/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (0.6.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in ./.local/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in ./.local/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (2.5.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in ./.local/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (59.6.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in ./.local/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (2.15.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in ./.local/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (3.12.1)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in ./.local/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (25.1.24)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in ./.local/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (3.4.0)\n",
            "Requirement already satisfied: tf-keras>=2.14.1 in ./.local/lib/python3.10/site-packages (from tensorflow-hub>=0.6.0->tf-models-official==2.15.0->object-detection==0.1) (2.15.1)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in ./.local/lib/python3.10/site-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official==2.15.0->object-detection==0.1) (0.1.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in ./.local/lib/python3.10/site-packages (from oauth2client->tf-models-official==2.15.0->object-detection==0.1) (0.4.1)\n",
            "Requirement already satisfied: rsa>=3.1.4 in ./.local/lib/python3.10/site-packages (from oauth2client->tf-models-official==2.15.0->object-detection==0.1) (4.9)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in ./.local/lib/python3.10/site-packages (from oauth2client->tf-models-official==2.15.0->object-detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in ./.local/lib/python3.10/site-packages (from seqeval->tf-models-official==2.15.0->object-detection==0.1) (1.6.1)\n",
            "Requirement already satisfied: etils[edc,enp,epath,epy,etree]>=1.6.0 in ./.local/lib/python3.10/site-packages (from tensorflow-datasets->tf-models-official==2.15.0->object-detection==0.1) (1.11.0)\n",
            "Requirement already satisfied: tensorflow-metadata in ./.local/lib/python3.10/site-packages (from tensorflow-datasets->tf-models-official==2.15.0->object-detection==0.1) (1.16.1)\n",
            "Requirement already satisfied: promise in ./.local/lib/python3.10/site-packages (from tensorflow-datasets->tf-models-official==2.15.0->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: click in ./.local/lib/python3.10/site-packages (from tensorflow-datasets->tf-models-official==2.15.0->object-detection==0.1) (8.1.8)\n",
            "Requirement already satisfied: array-record>=0.5.0 in ./.local/lib/python3.10/site-packages (from tensorflow-datasets->tf-models-official==2.15.0->object-detection==0.1) (0.6.0)\n",
            "Requirement already satisfied: simple-parsing in ./.local/lib/python3.10/site-packages (from tensorflow-datasets->tf-models-official==2.15.0->object-detection==0.1) (0.1.7)\n",
            "Requirement already satisfied: toml in ./.local/lib/python3.10/site-packages (from tensorflow-datasets->tf-models-official==2.15.0->object-detection==0.1) (0.10.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (0.37.1)\n",
            "Requirement already satisfied: importlib_resources in ./.local/lib/python3.10/site-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0->tensorflow-datasets->tf-models-official==2.15.0->object-detection==0.1) (6.5.2)\n",
            "Requirement already satisfied: zipp in /usr/lib/python3/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0->tensorflow-datasets->tf-models-official==2.15.0->object-detection==0.1) (1.0.0)\n",
            "Requirement already satisfied: fsspec in ./.local/lib/python3.10/site-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0->tensorflow-datasets->tf-models-official==2.15.0->object-detection==0.1) (2025.2.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in ./.local/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official==2.15.0->object-detection==0.1) (1.66.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./.local/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=1.6.7->tf-models-official==2.15.0->object-detection==0.1) (5.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.local/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.15.0->object-detection==0.1) (3.5.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in ./.local/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.15.0->object-detection==0.1) (1.4.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in ./.local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./.local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in ./.local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (3.1.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in ./.local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (1.2.1)\n",
            "Requirement already satisfied: webencodings in ./.local/lib/python3.10/site-packages (from bleach->kaggle>=1.3.9->tf-models-official==2.15.0->object-detection==0.1) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in ./.local/lib/python3.10/site-packages (from python-slugify->kaggle>=1.3.9->tf-models-official==2.15.0->object-detection==0.1) (1.3)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.15 in ./.local/lib/python3.10/site-packages (from simple-parsing->tensorflow-datasets->tf-models-official==2.15.0->object-detection==0.1) (0.16)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./.local/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (2.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in ./.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (3.0.2)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (3.2.0)\n",
            "Building wheels for collected packages: object-detection\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\n",
            "\u001b[?25h  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1697752 sha256=9b40813ebe4da5f54ed7f2bd60407b878c283cb316928b1928146027c2a0e046\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-xd_t6b76/wheels/d2/91/19/8fcd2d3d66b31c32d80d2d33f433eeb698c65e1c289e384aa1\n",
            "Successfully built object-detection\n",
            "Installing collected packages: object-detection\n",
            "  Attempting uninstall: object-detection\n",
            "    Found existing installation: object-detection 0.1\n",
            "    Uninstalling object-detection-0.1:\n",
            "      Successfully uninstalled object-detection-0.1\n",
            "Successfully installed object-detection-0.1\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: tensorflow==2.15.0 in ./.local/lib/python3.10/site-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (1.4.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (0.37.1)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (25.1.24)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (1.14.1)\n",
            "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow==2.15.0) (59.6.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (2.15.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (2.15.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (4.12.2)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (0.2.0)\n",
            "Requirement already satisfied: packaging in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (3.20.3)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (0.6.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (1.6.3)\n",
            "Requirement already satisfied: libclang>=13.0.0 in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (18.1.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (2.5.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (3.12.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (1.65.5)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (2.15.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (0.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow==2.15.0) (1.16.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow==2.15.0) (0.37.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in ./.local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in ./.local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.7)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in ./.local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.38.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in ./.local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.1.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in ./.local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./.local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.7.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in ./.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.4.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./.local/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2025.1.31)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.26.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in ./.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in ./.local/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.2.0)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: protobuf==3.20.3 in ./.local/lib/python3.10/site-packages (3.20.3)\n"
          ]
        }
      ],
      "source": [
        "# Install\n",
        "!pip install {HOMEFOLDER}models/research/\n",
        "if(MLENVIRONMENT == \"COLAB\"):\n",
        "    !pip install tensorflow==2.15.0\n",
        "    !pip install protobuf==3.20.3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6V7TrfUos-9E"
      },
      "source": [
        "Test the environment by running `model_builder_tf2_test.py` to make sure everything is working as expected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "wh_HPMOqWH9z",
        "outputId": "e73c893e-2eb2-47a1-d7c8-d16f89e5389c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-02-09 13:59:49.392645: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
            "2025-02-09 13:59:49.392678: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
            "2025-02-09 13:59:49.393643: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
            "2025-02-09 13:59:49.398125: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\r\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-02-09 13:59:49.936074: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2025-02-09 13:59:51.277589: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2025-02-09 13:59:51.332518: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2025-02-09 13:59:51.337252: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "Running tests under Python 3.10.12: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "2025-02-09 13:59:51.348712: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2025-02-09 13:59:51.353807: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2025-02-09 13:59:51.360266: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2025-02-09 13:59:51.471341: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2025-02-09 13:59:51.472597: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2025-02-09 13:59:51.473741: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2025-02-09 13:59:51.474861: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9910 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:0b:00.0, compute capability: 8.6\n",
            "WARNING:tensorflow:`tf.keras.layers.experimental.SyncBatchNormalization` endpoint is deprecated and will be removed in a future release. Please use `tf.keras.layers.BatchNormalization` with parameter `synchronized` set to True.\n",
            "W0209 13:59:51.598759 125202874818560 batch_normalization.py:1531] `tf.keras.layers.experimental.SyncBatchNormalization` endpoint is deprecated and will be removed in a future release. Please use `tf.keras.layers.BatchNormalization` with parameter `synchronized` set to True.\n",
            "/home/atharv/.local/lib/python3.10/site-packages/object_detection/builders/model_builder.py:1112: DeprecationWarning: The 'warn' function is deprecated, use 'warning' instead\n",
            "  logging.warn(('Building experimental DeepMAC meta-arch.'\n",
            "W0209 13:59:51.744079 125202874818560 model_builder.py:1112] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 0.69s\n",
            "I0209 13:59:52.033330 125202874818560 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 0.69s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.33s\n",
            "I0209 13:59:52.363874 125202874818560 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.33s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.17s\n",
            "I0209 13:59:52.533769 125202874818560 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.17s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.16s\n",
            "I0209 13:59:52.689704 125202874818560 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.16s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.14s\n",
            "I0209 13:59:53.828574 125202874818560 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.14s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I0209 13:59:53.839004 125202874818560 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.16s\n",
            "I0209 13:59:53.999792 125202874818560 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.16s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
            "I0209 13:59:54.009616 125202874818560 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n",
            "I0209 13:59:54.019622 125202874818560 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.06s\n",
            "I0209 13:59:54.077157 125202874818560 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.06s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.05s\n",
            "I0209 13:59:54.132299 125202874818560 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.05s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.06s\n",
            "I0209 13:59:54.190112 125202874818560 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.06s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.06s\n",
            "I0209 13:59:54.247292 125202874818560 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.06s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.06s\n",
            "I0209 13:59:54.302762 125202874818560 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.06s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.02s\n",
            "I0209 13:59:54.320015 125202874818560 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I0209 13:59:54.421696 125202874818560 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I0209 13:59:54.421789 125202874818560 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 64\n",
            "I0209 13:59:54.421823 125202874818560 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 3\n",
            "I0209 13:59:54.423238 125202874818560 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0209 13:59:54.439578 125202874818560 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0209 13:59:54.439642 125202874818560 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0209 13:59:54.483340 125202874818560 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0209 13:59:54.483425 125202874818560 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0209 13:59:54.595004 125202874818560 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0209 13:59:54.595096 125202874818560 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0209 13:59:54.703388 125202874818560 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0209 13:59:54.703478 125202874818560 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0209 13:59:54.864483 125202874818560 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0209 13:59:54.864578 125202874818560 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0209 13:59:55.042341 125202874818560 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0209 13:59:55.042436 125202874818560 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0209 13:59:55.262193 125202874818560 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0209 13:59:55.262303 125202874818560 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I0209 13:59:55.317264 125202874818560 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I0209 13:59:55.341488 125202874818560 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0209 13:59:55.372696 125202874818560 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I0209 13:59:55.372787 125202874818560 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 88\n",
            "I0209 13:59:55.372820 125202874818560 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 4\n",
            "I0209 13:59:55.373896 125202874818560 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0209 13:59:55.383625 125202874818560 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0209 13:59:55.383672 125202874818560 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0209 13:59:55.462725 125202874818560 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0209 13:59:55.462816 125202874818560 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0209 13:59:55.610502 125202874818560 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0209 13:59:55.610599 125202874818560 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0209 13:59:55.755867 125202874818560 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0209 13:59:55.755960 125202874818560 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0209 13:59:55.942460 125202874818560 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0209 13:59:55.942558 125202874818560 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0209 13:59:56.137450 125202874818560 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0209 13:59:56.137549 125202874818560 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0209 13:59:56.372600 125202874818560 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0209 13:59:56.372695 125202874818560 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I0209 13:59:56.472797 125202874818560 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I0209 13:59:56.490130 125202874818560 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0209 13:59:56.525970 125202874818560 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I0209 13:59:56.526059 125202874818560 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 112\n",
            "I0209 13:59:56.526093 125202874818560 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 5\n",
            "I0209 13:59:56.527160 125202874818560 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0209 13:59:56.537001 125202874818560 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0209 13:59:56.537051 125202874818560 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0209 13:59:56.610319 125202874818560 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0209 13:59:56.610407 125202874818560 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0209 13:59:56.894606 125202874818560 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0209 13:59:56.894706 125202874818560 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0209 13:59:57.060048 125202874818560 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0209 13:59:57.060141 125202874818560 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I0209 13:59:57.285068 125202874818560 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I0209 13:59:57.285165 125202874818560 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I0209 13:59:57.502772 125202874818560 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I0209 13:59:57.502870 125202874818560 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I0209 13:59:57.775535 125202874818560 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I0209 13:59:57.775629 125202874818560 efficientnet_model.py:143] round_filter input=320 output=352\n",
            "I0209 13:59:57.884440 125202874818560 efficientnet_model.py:143] round_filter input=1280 output=1408\n",
            "I0209 13:59:57.905245 125202874818560 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0209 13:59:57.941073 125202874818560 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I0209 13:59:57.941158 125202874818560 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 160\n",
            "I0209 13:59:57.941189 125202874818560 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 6\n",
            "I0209 13:59:57.942247 125202874818560 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I0209 13:59:57.954346 125202874818560 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I0209 13:59:57.954396 125202874818560 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0209 13:59:58.041351 125202874818560 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0209 13:59:58.041439 125202874818560 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0209 13:59:58.200556 125202874818560 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0209 13:59:58.200647 125202874818560 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0209 13:59:58.340831 125202874818560 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0209 13:59:58.340918 125202874818560 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I0209 13:59:58.601337 125202874818560 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I0209 13:59:58.601431 125202874818560 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I0209 13:59:58.870956 125202874818560 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I0209 13:59:58.871053 125202874818560 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I0209 13:59:59.195586 125202874818560 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I0209 13:59:59.195686 125202874818560 efficientnet_model.py:143] round_filter input=320 output=384\n",
            "I0209 13:59:59.303873 125202874818560 efficientnet_model.py:143] round_filter input=1280 output=1536\n",
            "I0209 13:59:59.324649 125202874818560 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0209 13:59:59.363573 125202874818560 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I0209 13:59:59.363662 125202874818560 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 224\n",
            "I0209 13:59:59.363692 125202874818560 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 7\n",
            "I0209 13:59:59.364751 125202874818560 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0209 13:59:59.376905 125202874818560 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0209 13:59:59.376951 125202874818560 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0209 13:59:59.453867 125202874818560 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0209 13:59:59.453952 125202874818560 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0209 13:59:59.643361 125202874818560 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0209 13:59:59.643453 125202874818560 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I0209 13:59:59.854742 125202874818560 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I0209 13:59:59.854840 125202874818560 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I0209 14:00:00.176776 125202874818560 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I0209 14:00:00.176879 125202874818560 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I0209 14:00:00.498070 125202874818560 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I0209 14:00:00.498168 125202874818560 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I0209 14:00:00.931184 125202874818560 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I0209 14:00:00.931291 125202874818560 efficientnet_model.py:143] round_filter input=320 output=448\n",
            "I0209 14:00:01.040616 125202874818560 efficientnet_model.py:143] round_filter input=1280 output=1792\n",
            "I0209 14:00:01.061643 125202874818560 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0209 14:00:01.293941 125202874818560 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I0209 14:00:01.294041 125202874818560 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 288\n",
            "I0209 14:00:01.294072 125202874818560 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 7\n",
            "I0209 14:00:01.295161 125202874818560 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0209 14:00:01.305083 125202874818560 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0209 14:00:01.305127 125202874818560 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0209 14:00:01.422469 125202874818560 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0209 14:00:01.422557 125202874818560 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0209 14:00:01.714865 125202874818560 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0209 14:00:01.714983 125202874818560 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I0209 14:00:01.985702 125202874818560 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I0209 14:00:01.985799 125202874818560 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I0209 14:00:02.359658 125202874818560 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I0209 14:00:02.359756 125202874818560 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I0209 14:00:02.733729 125202874818560 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I0209 14:00:02.733829 125202874818560 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I0209 14:00:03.218931 125202874818560 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I0209 14:00:03.219029 125202874818560 efficientnet_model.py:143] round_filter input=320 output=512\n",
            "I0209 14:00:03.379246 125202874818560 efficientnet_model.py:143] round_filter input=1280 output=2048\n",
            "I0209 14:00:03.400027 125202874818560 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0209 14:00:03.451848 125202874818560 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I0209 14:00:03.451945 125202874818560 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 384\n",
            "I0209 14:00:03.451977 125202874818560 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 8\n",
            "I0209 14:00:03.453050 125202874818560 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I0209 14:00:03.465683 125202874818560 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I0209 14:00:03.465743 125202874818560 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0209 14:00:03.595104 125202874818560 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0209 14:00:03.595199 125202874818560 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0209 14:00:03.883721 125202874818560 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0209 14:00:03.883822 125202874818560 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I0209 14:00:04.203938 125202874818560 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I0209 14:00:04.204036 125202874818560 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I0209 14:00:04.629460 125202874818560 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I0209 14:00:04.629555 125202874818560 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I0209 14:00:05.063261 125202874818560 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I0209 14:00:05.063359 125202874818560 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I0209 14:00:05.649019 125202874818560 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I0209 14:00:05.649115 125202874818560 efficientnet_model.py:143] round_filter input=320 output=576\n",
            "I0209 14:00:05.807867 125202874818560 efficientnet_model.py:143] round_filter input=1280 output=2304\n",
            "I0209 14:00:05.828641 125202874818560 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0209 14:00:06.101025 125202874818560 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I0209 14:00:06.101124 125202874818560 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 384\n",
            "I0209 14:00:06.101158 125202874818560 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 8\n",
            "I0209 14:00:06.102231 125202874818560 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I0209 14:00:06.115413 125202874818560 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I0209 14:00:06.115461 125202874818560 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0209 14:00:06.276631 125202874818560 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0209 14:00:06.276723 125202874818560 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I0209 14:00:06.653771 125202874818560 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I0209 14:00:06.653873 125202874818560 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I0209 14:00:07.024929 125202874818560 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I0209 14:00:07.025034 125202874818560 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I0209 14:00:07.578716 125202874818560 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I0209 14:00:07.578814 125202874818560 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I0209 14:00:08.113437 125202874818560 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I0209 14:00:08.113534 125202874818560 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I0209 14:00:08.811539 125202874818560 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I0209 14:00:08.811635 125202874818560 efficientnet_model.py:143] round_filter input=320 output=640\n",
            "I0209 14:00:09.028557 125202874818560 efficientnet_model.py:143] round_filter input=1280 output=2560\n",
            "I0209 14:00:09.050653 125202874818560 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 14.8s\n",
            "I0209 14:00:09.118191 125202874818560 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 14.8s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.01s\n",
            "I0209 14:00:09.220371 125202874818560 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.01s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I0209 14:00:09.221375 125202874818560 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I0209 14:00:09.221572 125202874818560 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I0209 14:00:09.222291 125202874818560 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I0209 14:00:09.222937 125202874818560 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I0209 14:00:09.223104 125202874818560 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I0209 14:00:09.223597 125202874818560 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 24 tests in 17.878s\n",
            "\n",
            "OK (skipped=1)\n"
          ]
        }
      ],
      "source": [
        "!python3 {HOMEFOLDER}models/research/object_detection/builders/model_builder_tf2_test.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6kMXxVJo5za"
      },
      "source": [
        "# 2. Auto-detect relevant tfrecord components"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WoA8HHf3I2t1"
      },
      "outputs": [],
      "source": [
        "datasetPath = '/home/atharv/dataset.zip'\n",
        "print(datasetPath)\n",
        "!unzip $datasetPath"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUd2wtfrqedy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import fnmatch\n",
        "\n",
        "def find_files(directory, pattern):\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for basename in files:\n",
        "            if fnmatch.fnmatch(basename, pattern):\n",
        "                filename = os.path.join(root, basename)\n",
        "                yield filename\n",
        "\n",
        "def set_tfrecord_variables(directory):\n",
        "    train_record_fname = ''\n",
        "    val_record_fname = ''\n",
        "    label_map_pbtxt_fname = ''\n",
        "\n",
        "    for tfrecord_file in find_files(directory, '*.tfrecord'):\n",
        "        if '/train/' in tfrecord_file:\n",
        "            train_record_fname = tfrecord_file\n",
        "        elif '/valid/' in tfrecord_file:\n",
        "            val_record_fname = tfrecord_file\n",
        "        elif '/test/' in tfrecord_file:\n",
        "            pass\n",
        "\n",
        "    for label_map_file in find_files(directory, '*_label_map.pbtxt'):\n",
        "        label_map_pbtxt_fname = label_map_file  # Assuming one common label map file\n",
        "\n",
        "    return train_record_fname, val_record_fname, label_map_pbtxt_fname\n",
        "\n",
        "\n",
        "train_record_fname, val_record_fname, label_map_pbtxt_fname = set_tfrecord_variables('/home/atharv')\n",
        "\n",
        "train_record_fname = '/home/atharv/train/coral-and-algae.tfrecord'\n",
        "val_record_fname = '/home/atharv/valid/coral-and-algae.tfrecord'\n",
        "label_map_pbtxt_fname = '/home/atharv/train/coral-and-algae_label_map.pbtxt'\n",
        "\n",
        "#if(MLENVIRONMENT==\"COLAB\"):\n",
        "    #train_record_fname = '/content/train/cubes-cones.tfrecord'\n",
        "    #val_record_fname = '/content/valid/cubes-cones.tfrecord'\n",
        "    #label_map_pbtxt_fname = '/content/train/cubes-cones_label_map.pbtxt'\n",
        "\n",
        "print(\"Train Record File:\", train_record_fname)\n",
        "print(\"Validation Record File:\", val_record_fname)\n",
        "print(\"Label Map File:\", label_map_pbtxt_fname)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGEUZYAMEZ6f"
      },
      "source": [
        "# 3.&nbsp;Training Configuration and Labels File Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2MAcgJ53STW"
      },
      "source": [
        "Download the pre-trained Limelight Base Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gN0EUEa3e5Un"
      },
      "outputs": [],
      "source": [
        "chosen_model = 'ssd-mobilenet-v2'\n",
        "MODELS_CONFIG = {\n",
        "    'ssd-mobilenet-v2': {\n",
        "        'model_name': 'ssd_mobilenet_v2_320x320_coco17_tpu-8',\n",
        "        'base_pipeline_file': 'limelight_ssd_mobilenet_v2_320x320_coco17_tpu-8.config',\n",
        "        'pretrained_checkpoint': 'limelight_ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz',\n",
        "    },\n",
        "}\n",
        "model_name = MODELS_CONFIG[chosen_model]['model_name']\n",
        "pretrained_checkpoint = MODELS_CONFIG[chosen_model]['pretrained_checkpoint']\n",
        "base_pipeline_file = MODELS_CONFIG[chosen_model]['base_pipeline_file']\n",
        "\n",
        "# Create \"mymodel\" folder for pre-trained weights and configuration files\n",
        "%cd ~\n",
        "%mkdir {HOMEFOLDER}models/mymodel/\n",
        "%cd {HOMEFOLDER}models/mymodel/\n",
        "%pwd\n",
        "\n",
        "# Download pre-trained model weights\n",
        "import tarfile\n",
        "download_tar = 'https://downloads.limelightvision.io/models/' + pretrained_checkpoint\n",
        "!wget {download_tar}\n",
        "tar = tarfile.open(pretrained_checkpoint)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "# Download training configuration file for model\n",
        "download_config = 'https://downloads.limelightvision.io/models/' + base_pipeline_file\n",
        "!wget {download_config}\n",
        "%cd ~\n",
        "\n",
        "# Set training parameters for the model\n",
        "num_steps = 40000\n",
        "checkpoint_every = 2000\n",
        "batch_size = 16\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMbr89qqgTVW"
      },
      "source": [
        "Generate Labels File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDyH_i3MgP1D"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Set file locations and get number of classes for config file\n",
        "pipeline_fname = HOMEFOLDER+'models/mymodel/' + base_pipeline_file\n",
        "fine_tune_checkpoint = HOMEFOLDER+'models/mymodel/' + model_name + '/checkpoint/ckpt-0'\n",
        "\n",
        "def get_num_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=90, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "    return len(category_index.keys())\n",
        "\n",
        "def get_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=90, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "\n",
        "    class_names = [category['name'] for category in category_index.values()]\n",
        "    return class_names\n",
        "\n",
        "def create_label_file(filename, labels):\n",
        "    with open(filename, 'w') as file:\n",
        "        for label in labels:\n",
        "            file.write(label + '\\n')\n",
        "\n",
        "\n",
        "num_classes = get_num_classes(label_map_pbtxt_fname)\n",
        "classes = get_classes(label_map_pbtxt_fname)\n",
        "\n",
        "print('Total classes:', num_classes)\n",
        "print(classes)\n",
        "\n",
        "\n",
        "#Generate labels file\n",
        "create_label_file(HOMEFOLDER + \"limelight_neural_detector_labels.txt\", classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwPyaIAXxyKu"
      },
      "source": [
        "Modify the base Limelight Model Configuration File\n",
        "\n",
        "Augmentation Options: https://github.com/tensorflow/models/blob/master/research/object_detection/protos/preprocessor.proto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5eA5ht3_yukT"
      },
      "outputs": [],
      "source": [
        "# Create custom configuration file by writing the dataset, model checkpoint, and training parameters into the base pipeline file\n",
        "import re\n",
        "\n",
        "print('writing custom configuration file')\n",
        "\n",
        "\n",
        "\n",
        "with open(pipeline_fname) as f:\n",
        "    s = f.read()\n",
        "with open('pipeline_file.config', 'w') as f:\n",
        "\n",
        "    # Set fine_tune_checkpoint path\n",
        "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
        "\n",
        "    # Set tfrecord files for train and test datasets\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', 'input_path: \"{}\"'.format(val_record_fname), s)\n",
        "\n",
        "    # Set label_map_path\n",
        "    s = re.sub(\n",
        "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
        "\n",
        "    # Set batch_size\n",
        "    s = re.sub('batch_size: [0-9]+',\n",
        "               'batch_size: {}'.format(batch_size), s)\n",
        "\n",
        "    # Set training steps, num_steps\n",
        "    s = re.sub('num_steps: [0-9]+',\n",
        "               'num_steps: {}'.format(num_steps), s)\n",
        "\n",
        "    # Set number of classes num_classes\n",
        "    s = re.sub('checkpoint_every_n: [0-9]+',\n",
        "               'num_classes: {}'.format(num_classes), s)\n",
        "\n",
        "    # Change fine-tune checkpoint type from \"classification\" to \"detection\"\n",
        "    s = re.sub(\n",
        "        'fine_tune_checkpoint_type: \"classification\"', 'fine_tune_checkpoint_type: \"{}\"'.format('detection'), s)\n",
        "\n",
        "    # If using ssd-mobilenet-v2, reduce learning rate\n",
        "    if chosen_model == 'ssd-mobilenet-v2':\n",
        "      s = re.sub('learning_rate_base: .8',\n",
        "                 'learning_rate_base: .004', s)\n",
        "\n",
        "      s = re.sub('warmup_learning_rate: 0.13333',\n",
        "                 'warmup_learning_rate: .0016666', s)\n",
        "\n",
        "    # If using efficientdet-d0, use fixed_shape_resizer instead of keep_aspect_ratio_resizer (because it isn't supported by TFLite)\n",
        "    if chosen_model == 'efficientdet-d0':\n",
        "      s = re.sub('keep_aspect_ratio_resizer', 'fixed_shape_resizer', s)\n",
        "      s = re.sub('pad_to_max_dimension: true', '', s)\n",
        "      s = re.sub('min_dimension', 'height', s)\n",
        "      s = re.sub('max_dimension', 'width', s)\n",
        "\n",
        "    f.write(s)\n",
        "\n",
        "# (Optional) Display the custom configuration file's contents\n",
        "# !cat pipeline_file.config\n",
        "# Set the path to the custom config file and the directory to store training checkpoints in\n",
        "pipeline_file = 'pipeline_file.config'\n",
        "model_dir = HOMEFOLDER+'training_progress/'\n",
        "print(\" \")\n",
        "print(model_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-19zML6oEO7l"
      },
      "source": [
        "# 4.&nbsp;Train Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxPj_QV43qD5"
      },
      "source": [
        "Once training starts, come back and click the refresh button within the tensorboard window to check training progress.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TI9iCCxoNlAL"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir '/content/training_progress/train'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejo07C1zXHzY"
      },
      "source": [
        "Fix TF 2.15 breaking changes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ltvi224axv3Y"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "import re\n",
        "\n",
        "original_path = '/home/atharv/.local/lib/python3.10/site-packages/tf_slim/data/tfexample_decoder.py'\n",
        "with open(original_path, 'r') as file:\n",
        "  content = file.read()\n",
        "  content = re.sub(r'import abc', 'import tensorflow as tf\\n\\nimport abc', content)\n",
        "  content = re.sub(r'control_flow_ops.case', 'tf.case', content)\n",
        "  content = re.sub(r'control_flow_ops.cond', 'tf.compat.v1.cond', content)\n",
        "with open(original_path, 'w') as file:\n",
        "  file.write(content)\n",
        "\n",
        "print(f\"File {original_path} fixed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjqYo9r9ffVx"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQTfZChVzzpZ"
      },
      "outputs": [],
      "source": [
        "!rm -rf {HOMEFOLDER}training_progress\n",
        "# Run training!\n",
        "!python3 {HOMEFOLDER}models/research/object_detection/model_main_tf2.py \\\n",
        "    --pipeline_config_path={pipeline_file} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\\n",
        "    --checkpoint_every_n={checkpoint_every} \\\n",
        "    --num_train_steps={num_steps} \\\n",
        "    --num_workers=2 \\\n",
        "    --sample_1_of_n_eval_examples=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHxbX4ZpzXIv"
      },
      "source": [
        "Feel free to stop training early. Check the 'training_progress' folder to see all training checkpoints.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPg8oMnQDYKl"
      },
      "source": [
        "# 5.&nbsp;Convert Model to TFLite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RaUU8tBlHifd"
      },
      "outputs": [],
      "source": [
        "#remove final output folder if it exists\n",
        "if os.path.exists(FINALOUTPUTFOLDER) and os.path.isdir(FINALOUTPUTFOLDER):\n",
        "  shutil.rmtree(FINALOUTPUTFOLDER)\n",
        "\n",
        "# Make a directory to store the trained TFLite model\n",
        "!mkdir {FINALOUTPUTFOLDER}\n",
        "print(FINALOUTPUTFOLDER)\n",
        "# Export graph\n",
        "# Path to training directory (the conversion script automatically chooses the highest checkpoint file)\n",
        "last_model_path = HOMEFOLDER+'training_progress'\n",
        "exporter_path = HOMEFOLDER+'models/research/object_detection/export_tflite_graph_tf2.py'\n",
        "output_directory = FINALOUTPUTFOLDER\n",
        "\n",
        "!python3 $exporter_path \\\n",
        "    --trained_checkpoint_dir $last_model_path \\\n",
        "    --output_directory $output_directory \\\n",
        "    --pipeline_config_path $pipeline_file\n",
        "\n",
        "# Convert to .tflite Flatbuffer\n",
        "import tensorflow as tf\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(FINALOUTPUTFOLDER+'/saved_model')\n",
        "tflite_model = converter.convert()\n",
        "model_path_32bit = FINALOUTPUTFOLDER+'/limelight_neural_detector_32bit.tflite'\n",
        "with open(model_path_32bit, 'wb') as f:\n",
        "  f.write(tflite_model)\n",
        "\n",
        "!cp {HOMEFOLDER}limelight_neural_detector_labels.txt {FINALOUTPUTFOLDER}\n",
        "!cp {HOMEFOLDER}models/mymodel/pipeline_file.config {FINALOUTPUTFOLDER}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqahbHU1suBi"
      },
      "outputs": [],
      "source": [
        "# Export graph\n",
        "# Path to training directory (the conversion script automatically chooses the highest checkpoint file)\n",
        "last_model_path = HOMEFOLDER+'training_progress'\n",
        "exporter_path = HOMEFOLDER+'models/research/object_detection/export_tflite_graph_tf2.py'\n",
        "output_directory = FINALOUTPUTFOLDER\n",
        "\n",
        "!python3 $exporter_path \\\n",
        "    --trained_checkpoint_dir $last_model_path \\\n",
        "    --output_directory $output_directory \\\n",
        "    --pipeline_config_path $pipeline_file\n",
        "\n",
        "# Convert to .tflite Flatbuffer\n",
        "import tensorflow as tf\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(FINALOUTPUTFOLDER+'/saved_model')\n",
        "tflite_model = converter.convert()\n",
        "model_path_32bit = FINALOUTPUTFOLDER+'/limelight_neural_detector_32bit.tflite'\n",
        "with open(model_path_32bit, 'wb') as f:\n",
        "  f.write(tflite_model)\n",
        "\n",
        "!cp {HOMEFOLDER}limelight_neural_detector_labels.txt {FINALOUTPUTFOLDER}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTyqlXFTJ0Uv"
      },
      "source": [
        "# 6. Quantize model\n",
        "The \"TFLiteConverter\" module will perform [post-training quantization](https://www.tensorflow.org/lite/performance/post_training_quantization) on the model. To quantize the model, we need to provide a set of example images. We will extract 100 images from the training tfrecord and place said images into the \"extracted_samples\" folder.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSNZtfj_k3NP"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import io\n",
        "from PIL import Image\n",
        "\n",
        "def extract_images_from_tfrecord(tfrecord_path, output_folder, num_samples=100):\n",
        "    # Make sure the output directory exists\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Initialize a counter for the number of images saved\n",
        "    saved_images = 0\n",
        "\n",
        "    # Read the TFRecord file\n",
        "    raw_dataset = tf.data.TFRecordDataset(tfrecord_path)\n",
        "    for raw_record in raw_dataset.take(num_samples):\n",
        "        example = tf.train.Example()\n",
        "        example.ParseFromString(raw_record.numpy())\n",
        "\n",
        "        # Extract the image data (change 'image/encoded' if necessary)\n",
        "        image_data = example.features.feature['image/encoded'].bytes_list.value[0]\n",
        "\n",
        "        # Decode the image data and save as a file\n",
        "        image = Image.open(io.BytesIO(image_data))\n",
        "        image.save(os.path.join(output_folder, f'image_{saved_images}.png'))\n",
        "\n",
        "        saved_images += 1\n",
        "        if saved_images >= num_samples:\n",
        "            break\n",
        "\n",
        "    print(f\"Extracted {saved_images} images to {output_folder}\")\n",
        "\n",
        "# Set the path to your TFRecord file and the output directory\n",
        "tfrecord_path = train_record_fname\n",
        "extracted_sample_folder = HOMEFOLDER+'extracted_samples'\n",
        "\n",
        "#remove sample folder if it exists\n",
        "if os.path.exists(extracted_sample_folder) and os.path.isdir(extracted_sample_folder):\n",
        "  shutil.rmtree(extracted_sample_folder)\n",
        "\n",
        "# Extract images\n",
        "extract_images_from_tfrecord(tfrecord_path, extracted_sample_folder)\n",
        "\n",
        "\n",
        "# Get list of all images in train directory\n",
        "from google.cloud import storage\n",
        "import glob\n",
        "\n",
        "quant_image_list=[]\n",
        "if(MLENVIRONMENT==\"COLAB\"):\n",
        "\n",
        "    jpg_file_list = glob.glob(extracted_sample_folder + '/*.jpg')\n",
        "    jpeg_file_list = glob.glob(extracted_sample_folder + '/*.jpeg')\n",
        "    JPG_file_list = glob.glob(extracted_sample_folder + '/*.JPG')\n",
        "    png_file_list = glob.glob(extracted_sample_folder + '/*.png')\n",
        "    bmp_file_list = glob.glob(extracted_sample_folder + '/*.bmp')\n",
        "    quant_image_list = jpg_file_list + JPG_file_list + png_file_list + bmp_file_list\n",
        "\n",
        "print(\"pulling samples from \" + extracted_sample_folder)\n",
        "print(\"samples: \" + str(len(quant_image_list)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORzx0XRErSLV"
      },
      "outputs": [],
      "source": [
        "# A generator that provides a representative dataset\n",
        "# Code modified from https://colab.research.google.com/github/google-coral/tutorials/blob/master/retrain_classification_ptq_tf2.ipynb\n",
        "\n",
        "# First, get input details for model so we know how to preprocess images\n",
        "interpreter = tf.lite.Interpreter(model_path=model_path_32bit)\n",
        "interpreter.allocate_tensors()\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "height = input_details[0]['shape'][1]\n",
        "width = input_details[0]['shape'][2]\n",
        "\n",
        "import random\n",
        "\n",
        "def representative_data_gen():\n",
        "  dataset_list = quant_image_list\n",
        "  quant_num = 300\n",
        "  for i in range(quant_num):\n",
        "    pick_me = random.choice(dataset_list)\n",
        "    print(pick_me)\n",
        "    image = tf.io.read_file(pick_me)\n",
        "\n",
        "    if pick_me.endswith('.jpg') or pick_me.endswith('.JPG') or pick_me.endswith('.jpeg'):\n",
        "      image = tf.io.decode_jpeg(image, channels=3)\n",
        "    elif pick_me.endswith('.png'):\n",
        "      image = tf.io.decode_png(image, channels=3)\n",
        "    elif pick_me.endswith('.bmp'):\n",
        "      image = tf.io.decode_bmp(image, channels=3)\n",
        "\n",
        "    image = tf.image.resize(image, [width, height])  # TO DO: Replace 300s with an automatic way of reading network input size\n",
        "    image = tf.cast(image / 255., tf.float32)\n",
        "    image = tf.expand_dims(image, 0)\n",
        "    yield [image]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqtu98mzebEj"
      },
      "source": [
        "Finally, we'll initialize the TFLiteConverter module, point it at the TFLite graph we generated in Step 6, and provide it with the representative dataset generator function we created in the previous code block. We'll configure the converter to quantize the model's weight values to INT8 format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ox0bGDWds_Ce"
      },
      "outputs": [],
      "source": [
        "# Initialize converter module\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(FINALOUTPUTFOLDER+'/saved_model')\n",
        "print(\"initialized converter\")\n",
        "# This enables quantization\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "# This sets the representative dataset for quantization\n",
        "converter.representative_dataset = representative_data_gen\n",
        "# This ensures that if any ops can't be quantized, the converter throws an error\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "# For full integer quantization, though supported types defaults to int8 only, we explicitly declare it for clarity.\n",
        "converter.target_spec.supported_types = [tf.int8]\n",
        "# These set the input tensors to uint8 and output tensors to float32\n",
        "converter.inference_input_type = tf.uint8\n",
        "converter.inference_output_type = tf.float32\n",
        "print(\"begin conversion\")\n",
        "tflite_model = converter.convert()\n",
        "print(\"conversion complete\")\n",
        "\n",
        "with open(FINALOUTPUTFOLDER+'/limelight_neural_detector_8bit.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFsuasvxFHo8"
      },
      "source": [
        "# 7. Compile Model for Limelight & Download\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peawOI_z0DHt"
      },
      "source": [
        "Install Coral Compiler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUd_SNC0JSq0"
      },
      "outputs": [],
      "source": [
        "! curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n",
        "! echo \"deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\" | sudo tee /etc/apt/sources.list.d/coral-edgetpu.list\n",
        "! sudo apt-get update\n",
        "! sudo apt-get install edgetpu-compiler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usfmdtSiJuuC"
      },
      "source": [
        "Compile the previously-generated 8-bit model for Google Coral"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mULCY0nb0ahH"
      },
      "outputs": [],
      "source": [
        "!cd {FINALOUTPUTFOLDER} && pwd && edgetpu_compiler limelight_neural_detector_8bit.tflite && pwd && mv limelight_neural_detector_8bit_edgetpu.tflite limelight_neural_detector_coral.tflite && rm limelight_neural_detector_8bit_edgetpu.log"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqGy2FgzKomN"
      },
      "source": [
        "Zip models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nCdUouYJjQM"
      },
      "outputs": [],
      "source": [
        "!rm {HOMEFOLDER}limelight_detectors.zip\n",
        "!zip -r {HOMEFOLDER}limelight_detectors.zip {FINALOUTPUTFOLDER}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHgbpkQue-ZR"
      },
      "source": [
        "Download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AmjqvKuuK8ZR"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download(HOMEFOLDER+'limelight_detectors.zip')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "05N8FeXHcQp3",
        "xmROIG9zaS9G",
        "eGEUZYAMEZ6f",
        "-19zML6oEO7l",
        "kPg8oMnQDYKl",
        "VTyqlXFTJ0Uv",
        "XFsuasvxFHo8"
      ],
      "gpuClass": "premium",
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "dac6b1a68a930bf8a24417228a96ab80b19f2aa97bc2d428affc356154b4740f"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}