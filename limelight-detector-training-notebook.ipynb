{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Random-Coder-Dude/Realtime-Object-Detection/blob/main/limelight-detector-training-notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJVo_xMPf4LY"
      },
      "source": [
        "![TrainingNotebookLogo.png](https://downloads.limelightvision.io/content/TrainingNotebookLogo.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72xbzFQrPL5q"
      },
      "source": [
        "To train a neural object detector for Limelight, click the \"play\" button on each code block. Pay extra attention to any \"â—\" you see. By the end of this tutorial, you will have downloaded a .zip file containing your model and label files.\n",
        "\n",
        "See https://docs.limelightvision.io/docs/docs-limelight/pipeline-neural/training-your-own-detector for a more in-depth tutorial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05N8FeXHcQp3"
      },
      "source": [
        "# 1. Install The Object Detection Package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ypWGYdPlLRUN",
        "outputId": "def4166d-f660-4acc-dc40-a31b6a754471",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'models' already exists and is not an empty directory.\n",
            "remote: Enumerating objects: 3055, done.\u001b[K\n",
            "remote: Counting objects: 100% (3055/3055), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1359/1359), done.\u001b[K\n",
            "remote: Total 1824 (delta 1223), reused 703 (delta 446), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (1824/1824), 10.05 MiB | 7.01 MiB/s, done.\n",
            "Resolving deltas: 100% (1223/1223), completed with 739 local objects.\n",
            "From https://github.com/tensorflow/models\n",
            " * branch            ad1f7b56943998864db8f5db0706950e93bb7d81 -> FETCH_HEAD\n",
            "HEAD is now at ad1f7b5 adjust folder path\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: protobuf==3.20.3 in ./.local/lib/python3.10/site-packages (3.20.3)\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "import os\n",
        "tmpModelPath ='/content/models'\n",
        "if os.path.exists(tmpModelPath) and os.path.isdir(tmpModelPath):\n",
        "  shutil.rmtree(tmpModelPath)\n",
        "\n",
        "MLENVIRONMENT=\"COLAB\"\n",
        "!git clone --depth 1 https://github.com/tensorflow/models\n",
        "!cd models && git fetch --depth 1 origin ad1f7b56943998864db8f5db0706950e93bb7d81 && git checkout ad1f7b56943998864db8f5db0706950e93bb7d81\n",
        "!pip install protobuf==3.20.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "6QPmVBSlLTzM",
        "outputId": "9e847637-bbc7-4c2e-f531-08d4293e5cf2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.10.12 (main, Jan 17 2025, 14:35:34) [GCC 11.4.0]\n",
            "colab env setup\n",
            "/home/atharv/\n",
            "/home/atharv/models/research\r\n"
          ]
        }
      ],
      "source": [
        "# Environment Setup\n",
        "import os\n",
        "import sys\n",
        "import re\n",
        "\n",
        "print(sys.version)\n",
        "if(MLENVIRONMENT == \"COLAB\"):\n",
        "    print(\"colab env setup\")\n",
        "    os.environ[\"HOMEFOLDER\"] = \"/home/atharv/\"\n",
        "    HOMEFOLDER = '{HOMEFOLDER}'.format(**os.environ)\n",
        "    FINALOUTPUTFOLDER_DIRNAME = 'final_output'\n",
        "    FINALOUTPUTFOLDER = HOMEFOLDER+FINALOUTPUTFOLDER_DIRNAME\n",
        "    print(HOMEFOLDER)\n",
        "\n",
        "# Copy setup files into models/research folder\n",
        "!cd {HOMEFOLDER}models/research && pwd && protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "# Modify setup.py\n",
        "with open(HOMEFOLDER+'models/research/object_detection/packages/tf2/setup.py') as f:\n",
        "    s = f.read()\n",
        "\n",
        "with open(HOMEFOLDER+'models/research/setup.py', 'w') as f:\n",
        "    if(MLENVIRONMENT == \"COLAB\"):\n",
        "        s = re.sub('tf-models-official>=2.5.1','tf-models-official==2.15.0', s)\n",
        "        f.write(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "OLDnCkLLwLr6",
        "outputId": "2899a2fa-8ed7-4df3-8c66-eaa1ac7ed5eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Processing ./models/research\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25hRequirement already satisfied: Cython in ./.local/lib/python3.10/site-packages (from object-detection==0.1) (3.0.11)\n",
            "Requirement already satisfied: apache-beam in ./.local/lib/python3.10/site-packages (from object-detection==0.1) (2.62.0)\n",
            "Requirement already satisfied: avro-python3 in ./.local/lib/python3.10/site-packages (from object-detection==0.1) (1.10.2)\n",
            "Requirement already satisfied: contextlib2 in ./.local/lib/python3.10/site-packages (from object-detection==0.1) (21.6.0)\n",
            "Requirement already satisfied: keras in ./.local/lib/python3.10/site-packages (from object-detection==0.1) (2.15.0)\n",
            "Requirement already satisfied: lvis in ./.local/lib/python3.10/site-packages (from object-detection==0.1) (0.5.3)\n",
            "Requirement already satisfied: lxml in ./.local/lib/python3.10/site-packages (from object-detection==0.1) (5.3.0)\n",
            "Requirement already satisfied: matplotlib in ./.local/lib/python3.10/site-packages (from object-detection==0.1) (3.10.0)\n",
            "Requirement already satisfied: pandas in ./.local/lib/python3.10/site-packages (from object-detection==0.1) (2.2.3)\n",
            "Requirement already satisfied: pillow in /usr/lib/python3/dist-packages (from object-detection==0.1) (9.0.1)\n",
            "Requirement already satisfied: pycocotools in ./.local/lib/python3.10/site-packages (from object-detection==0.1) (2.0.8)\n",
            "Requirement already satisfied: pyparsing==2.4.7 in /usr/lib/python3/dist-packages (from object-detection==0.1) (2.4.7)\n",
            "Requirement already satisfied: sacrebleu<=2.2.0 in ./.local/lib/python3.10/site-packages (from object-detection==0.1) (2.2.0)\n",
            "Requirement already satisfied: scipy in ./.local/lib/python3.10/site-packages (from object-detection==0.1) (1.15.1)\n",
            "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from object-detection==0.1) (1.16.0)\n",
            "Requirement already satisfied: tensorflow_io in ./.local/lib/python3.10/site-packages (from object-detection==0.1) (0.37.1)\n",
            "Requirement already satisfied: tf-models-official==2.15.0 in ./.local/lib/python3.10/site-packages (from object-detection==0.1) (2.15.0)\n",
            "Requirement already satisfied: tf-slim in ./.local/lib/python3.10/site-packages (from object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: sentencepiece in ./.local/lib/python3.10/site-packages (from tf-models-official==2.15.0->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: psutil>=5.4.3 in ./.local/lib/python3.10/site-packages (from tf-models-official==2.15.0->object-detection==0.1) (6.1.1)\n",
            "Requirement already satisfied: opencv-python-headless in ./.local/lib/python3.10/site-packages (from tf-models-official==2.15.0->object-detection==0.1) (4.11.0.86)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in ./.local/lib/python3.10/site-packages (from tf-models-official==2.15.0->object-detection==0.1) (2.160.0)\n",
            "Requirement already satisfied: py-cpuinfo>=3.3.0 in ./.local/lib/python3.10/site-packages (from tf-models-official==2.15.0->object-detection==0.1) (9.0.0)\n",
            "Requirement already satisfied: seqeval in ./.local/lib/python3.10/site-packages (from tf-models-official==2.15.0->object-detection==0.1) (1.2.2)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in ./.local/lib/python3.10/site-packages (from tf-models-official==2.15.0->object-detection==0.1) (6.0.2)\n",
            "Requirement already satisfied: gin-config in ./.local/lib/python3.10/site-packages (from tf-models-official==2.15.0->object-detection==0.1) (0.5.0)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in ./.local/lib/python3.10/site-packages (from tf-models-official==2.15.0->object-detection==0.1) (1.6.17)\n",
            "Requirement already satisfied: tensorflow~=2.15.0 in ./.local/lib/python3.10/site-packages (from tf-models-official==2.15.0->object-detection==0.1) (2.15.0)\n",
            "Requirement already satisfied: tensorflow-model-optimization>=0.4.1 in ./.local/lib/python3.10/site-packages (from tf-models-official==2.15.0->object-detection==0.1) (0.8.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in ./.local/lib/python3.10/site-packages (from tf-models-official==2.15.0->object-detection==0.1) (0.16.1)\n",
            "Requirement already satisfied: oauth2client in ./.local/lib/python3.10/site-packages (from tf-models-official==2.15.0->object-detection==0.1) (4.1.3)\n",
            "Requirement already satisfied: tensorflow-text~=2.15.0 in ./.local/lib/python3.10/site-packages (from tf-models-official==2.15.0->object-detection==0.1) (2.15.0)\n",
            "Requirement already satisfied: tensorflow-datasets in ./.local/lib/python3.10/site-packages (from tf-models-official==2.15.0->object-detection==0.1) (4.9.7)\n",
            "Requirement already satisfied: numpy>=1.20 in ./.local/lib/python3.10/site-packages (from tf-models-official==2.15.0->object-detection==0.1) (1.26.4)\n",
            "Requirement already satisfied: immutabledict in ./.local/lib/python3.10/site-packages (from tf-models-official==2.15.0->object-detection==0.1) (4.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in ./.local/lib/python3.10/site-packages (from pandas->object-detection==0.1) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in ./.local/lib/python3.10/site-packages (from pandas->object-detection==0.1) (2025.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->object-detection==0.1) (2022.1)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in ./.local/lib/python3.10/site-packages (from sacrebleu<=2.2.0->object-detection==0.1) (0.9.0)\n",
            "Requirement already satisfied: colorama in /usr/lib/python3/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (0.4.4)\n",
            "Requirement already satisfied: regex in ./.local/lib/python3.10/site-packages (from sacrebleu<=2.2.0->object-detection==0.1) (2024.11.6)\n",
            "Requirement already satisfied: portalocker in ./.local/lib/python3.10/site-packages (from sacrebleu<=2.2.0->object-detection==0.1) (3.1.1)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in ./.local/lib/python3.10/site-packages (from tf-slim->object-detection==0.1) (1.4.0)\n",
            "Requirement already satisfied: cloudpickle~=2.2.1 in ./.local/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (2.2.1)\n",
            "Requirement already satisfied: pyarrow-hotfix<1 in ./.local/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (0.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.24.0 in ./.local/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (2.32.3)\n",
            "Requirement already satisfied: grpcio!=1.48.0,!=1.59.*,!=1.60.*,!=1.61.*,!=1.62.0,!=1.62.1,<1.66.0,<2,>=1.33.1 in ./.local/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (1.65.5)\n",
            "Requirement already satisfied: fasteners<1.0,>=0.3 in ./.local/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (0.19)\n",
            "Requirement already satisfied: pymongo<5.0.0,>=3.8.0 in ./.local/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (4.11)\n",
            "Requirement already satisfied: jsonpickle<4.0.0,>=3.0.0 in ./.local/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (3.4.2)\n",
            "Requirement already satisfied: sortedcontainers>=2.4.0 in ./.local/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (2.4.0)\n",
            "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in ./.local/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (2.7.3)\n",
            "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in ./.local/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (0.3.1.1)\n",
            "Requirement already satisfied: httplib2<0.23.0,>=0.8 in /usr/lib/python3/dist-packages (from apache-beam->object-detection==0.1) (0.20.2)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in ./.local/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (4.23.0)\n",
            "Requirement already satisfied: protobuf!=4.0.*,!=4.21.*,!=4.22.0,!=4.23.*,!=4.24.*,<6.0.0.dev0,>=3.20.3 in ./.local/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (3.20.3)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in ./.local/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Requirement already satisfied: packaging>=22.0 in ./.local/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (24.2)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in ./.local/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (1.4.2)\n",
            "Requirement already satisfied: redis<6,>=5.0.0 in ./.local/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (5.2.1)\n",
            "Requirement already satisfied: objsize<0.8.0,>=0.6.1 in ./.local/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (0.7.1)\n",
            "Requirement already satisfied: pyarrow<17.0.0,>=3.0.0 in ./.local/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (16.1.0)\n",
            "Requirement already satisfied: orjson<4,>=3.9.7 in ./.local/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (3.10.15)\n",
            "Requirement already satisfied: fastavro<2,>=0.23.6 in ./.local/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (1.10.0)\n",
            "Requirement already satisfied: proto-plus<2,>=1.7.1 in ./.local/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (1.26.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.0 in ./.local/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (4.12.2)\n",
            "Requirement already satisfied: zstandard<1,>=0.18.0 in ./.local/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (0.23.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in ./.local/lib/python3.10/site-packages (from lvis->object-detection==0.1) (4.11.0.86)\n",
            "Requirement already satisfied: cycler>=0.10.0 in ./.local/lib/python3.10/site-packages (from lvis->object-detection==0.1) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in ./.local/lib/python3.10/site-packages (from lvis->object-detection==0.1) (1.4.8)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in ./.local/lib/python3.10/site-packages (from matplotlib->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in ./.local/lib/python3.10/site-packages (from matplotlib->object-detection==0.1) (4.55.8)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.37.1 in ./.local/lib/python3.10/site-packages (from tensorflow_io->object-detection==0.1) (0.37.1)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in ./.local/lib/python3.10/site-packages (from google-api-python-client>=1.6.7->tf-models-official==2.15.0->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in ./.local/lib/python3.10/site-packages (from google-api-python-client>=1.6.7->tf-models-official==2.15.0->object-detection==0.1) (2.24.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in ./.local/lib/python3.10/site-packages (from google-api-python-client>=1.6.7->tf-models-official==2.15.0->object-detection==0.1) (2.38.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in ./.local/lib/python3.10/site-packages (from google-api-python-client>=1.6.7->tf-models-official==2.15.0->object-detection==0.1) (4.1.1)\n",
            "Requirement already satisfied: docopt in ./.local/lib/python3.10/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n",
            "Requirement already satisfied: referencing>=0.28.4 in ./.local/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object-detection==0.1) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in ./.local/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object-detection==0.1) (0.22.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in ./.local/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object-detection==0.1) (25.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./.local/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object-detection==0.1) (2024.10.1)\n",
            "Requirement already satisfied: urllib3 in /usr/lib/python3/dist-packages (from kaggle>=1.3.9->tf-models-official==2.15.0->object-detection==0.1) (1.26.5)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in ./.local/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official==2.15.0->object-detection==0.1) (2025.1.31)\n",
            "Requirement already satisfied: python-slugify in ./.local/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official==2.15.0->object-detection==0.1) (8.0.4)\n",
            "Requirement already satisfied: tqdm in ./.local/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official==2.15.0->object-detection==0.1) (4.67.1)\n",
            "Requirement already satisfied: bleach in ./.local/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official==2.15.0->object-detection==0.1) (6.2.0)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in ./.local/lib/python3.10/site-packages (from pymongo<5.0.0,>=3.8.0->apache-beam->object-detection==0.1) (2.7.0)\n",
            "Requirement already satisfied: async-timeout>=4.0.3 in ./.local/lib/python3.10/site-packages (from redis<6,>=5.0.0->apache-beam->object-detection==0.1) (5.0.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.4.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in ./.local/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (2.5.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in ./.local/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (3.4.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in ./.local/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (18.1.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in ./.local/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (2.15.0)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in ./.local/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in ./.local/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (25.1.24)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in ./.local/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (1.14.1)\n",
            "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (59.6.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in ./.local/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (3.12.1)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./.local/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (0.6.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in ./.local/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in ./.local/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in ./.local/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (2.15.2)\n",
            "Requirement already satisfied: tf-keras>=2.14.1 in ./.local/lib/python3.10/site-packages (from tensorflow-hub>=0.6.0->tf-models-official==2.15.0->object-detection==0.1) (2.15.1)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in ./.local/lib/python3.10/site-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official==2.15.0->object-detection==0.1) (0.1.9)\n",
            "Requirement already satisfied: rsa>=3.1.4 in ./.local/lib/python3.10/site-packages (from oauth2client->tf-models-official==2.15.0->object-detection==0.1) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in ./.local/lib/python3.10/site-packages (from oauth2client->tf-models-official==2.15.0->object-detection==0.1) (0.4.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in ./.local/lib/python3.10/site-packages (from oauth2client->tf-models-official==2.15.0->object-detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in ./.local/lib/python3.10/site-packages (from seqeval->tf-models-official==2.15.0->object-detection==0.1) (1.6.1)\n",
            "Requirement already satisfied: array-record>=0.5.0 in ./.local/lib/python3.10/site-packages (from tensorflow-datasets->tf-models-official==2.15.0->object-detection==0.1) (0.6.0)\n",
            "Requirement already satisfied: tensorflow-metadata in ./.local/lib/python3.10/site-packages (from tensorflow-datasets->tf-models-official==2.15.0->object-detection==0.1) (1.16.1)\n",
            "Requirement already satisfied: toml in ./.local/lib/python3.10/site-packages (from tensorflow-datasets->tf-models-official==2.15.0->object-detection==0.1) (0.10.2)\n",
            "Requirement already satisfied: promise in ./.local/lib/python3.10/site-packages (from tensorflow-datasets->tf-models-official==2.15.0->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: etils[edc,enp,epath,epy,etree]>=1.6.0 in ./.local/lib/python3.10/site-packages (from tensorflow-datasets->tf-models-official==2.15.0->object-detection==0.1) (1.11.0)\n",
            "Requirement already satisfied: click in /usr/lib/python3/dist-packages (from tensorflow-datasets->tf-models-official==2.15.0->object-detection==0.1) (8.0.3)\n",
            "Requirement already satisfied: simple-parsing in ./.local/lib/python3.10/site-packages (from tensorflow-datasets->tf-models-official==2.15.0->object-detection==0.1) (0.1.7)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (0.37.1)\n",
            "Requirement already satisfied: zipp in /usr/lib/python3/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0->tensorflow-datasets->tf-models-official==2.15.0->object-detection==0.1) (1.0.0)\n",
            "Requirement already satisfied: importlib_resources in ./.local/lib/python3.10/site-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0->tensorflow-datasets->tf-models-official==2.15.0->object-detection==0.1) (6.5.2)\n",
            "Requirement already satisfied: fsspec in ./.local/lib/python3.10/site-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0->tensorflow-datasets->tf-models-official==2.15.0->object-detection==0.1) (2025.2.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in ./.local/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official==2.15.0->object-detection==0.1) (1.66.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./.local/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=1.6.7->tf-models-official==2.15.0->object-detection==0.1) (5.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.local/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.15.0->object-detection==0.1) (3.5.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in ./.local/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.15.0->object-detection==0.1) (1.4.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in ./.local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (3.1.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./.local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (0.7.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in ./.local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (3.7)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in ./.local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (1.2.1)\n",
            "Requirement already satisfied: webencodings in ./.local/lib/python3.10/site-packages (from bleach->kaggle>=1.3.9->tf-models-official==2.15.0->object-detection==0.1) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in ./.local/lib/python3.10/site-packages (from python-slugify->kaggle>=1.3.9->tf-models-official==2.15.0->object-detection==0.1) (1.3)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.15 in ./.local/lib/python3.10/site-packages (from simple-parsing->tensorflow-datasets->tf-models-official==2.15.0->object-detection==0.1) (0.16)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./.local/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (2.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in ./.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (3.0.2)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (3.2.0)\n",
            "Building wheels for collected packages: object-detection\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\n",
            "\u001b[?25h  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1697752 sha256=d923fdeacc69c8d4bbbf250eb82a4d10345a6d0294cd441cd7a118112ace7121\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-hhhrirws/wheels/d2/91/19/8fcd2d3d66b31c32d80d2d33f433eeb698c65e1c289e384aa1\n",
            "Successfully built object-detection\n",
            "Installing collected packages: object-detection\n",
            "  Attempting uninstall: object-detection\n",
            "    Found existing installation: object-detection 0.1\n",
            "    Uninstalling object-detection-0.1:\n",
            "      Successfully uninstalled object-detection-0.1\n",
            "Successfully installed object-detection-0.1\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: tensorflow==2.15.0 in ./.local/lib/python3.10/site-packages (2.15.0)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (18.1.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (0.37.1)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (25.1.24)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (3.12.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (4.12.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (1.6.3)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (1.14.1)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (0.6.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (2.5.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (1.4.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (1.65.5)\n",
            "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow==2.15.0) (59.6.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (2.15.0)\n",
            "Requirement already satisfied: packaging in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (24.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow==2.15.0) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (2.15.2)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (3.20.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow==2.15.0) (0.37.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in ./.local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.2.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in ./.local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./.local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in ./.local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.1.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in ./.local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.38.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in ./.local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.7)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in ./.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./.local/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2025.1.31)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.26.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in ./.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in ./.local/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.2.0)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: protobuf==3.20.3 in ./.local/lib/python3.10/site-packages (3.20.3)\n"
          ]
        }
      ],
      "source": [
        "# Install\n",
        "!pip install {HOMEFOLDER}models/research/\n",
        "if(MLENVIRONMENT == \"COLAB\"):\n",
        "    !pip install tensorflow==2.15.0\n",
        "    !pip install protobuf==3.20.3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6V7TrfUos-9E"
      },
      "source": [
        "Test the environment by running `model_builder_tf2_test.py` to make sure everything is working as expected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "wh_HPMOqWH9z",
        "outputId": "70cc3360-982a-4926-afd4-93bd7308aa70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-02-08 17:35:23.667684: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
            "2025-02-08 17:35:23.667716: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
            "2025-02-08 17:35:23.668566: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
            "2025-02-08 17:35:23.672823: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\r\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-02-08 17:35:24.219673: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Running tests under Python 3.10.12: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "2025-02-08 17:35:25.629487: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9974 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:0b:00.0, compute capability: 8.6\n",
            "WARNING:tensorflow:`tf.keras.layers.experimental.SyncBatchNormalization` endpoint is deprecated and will be removed in a future release. Please use `tf.keras.layers.BatchNormalization` with parameter `synchronized` set to True.\n",
            "W0208 17:35:25.755439 123593023389696 batch_normalization.py:1531] `tf.keras.layers.experimental.SyncBatchNormalization` endpoint is deprecated and will be removed in a future release. Please use `tf.keras.layers.BatchNormalization` with parameter `synchronized` set to True.\n",
            "/home/atharv/.local/lib/python3.10/site-packages/object_detection/builders/model_builder.py:1112: DeprecationWarning: The 'warn' function is deprecated, use 'warning' instead\n",
            "  logging.warn(('Building experimental DeepMAC meta-arch.'\n",
            "W0208 17:35:25.901302 123593023389696 model_builder.py:1112] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 0.68s\n",
            "I0208 17:35:26.178137 123593023389696 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 0.68s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.33s\n",
            "I0208 17:35:26.511635 123593023389696 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.33s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.17s\n",
            "I0208 17:35:26.678817 123593023389696 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.17s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.16s\n",
            "I0208 17:35:26.834368 123593023389696 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.16s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.13s\n",
            "I0208 17:35:27.964126 123593023389696 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.13s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I0208 17:35:27.973258 123593023389696 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.15s\n",
            "I0208 17:35:28.121043 123593023389696 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.15s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
            "I0208 17:35:28.130593 123593023389696 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n",
            "I0208 17:35:28.140272 123593023389696 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.06s\n",
            "I0208 17:35:28.196433 123593023389696 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.06s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.05s\n",
            "I0208 17:35:28.250365 123593023389696 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.05s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.06s\n",
            "I0208 17:35:28.306816 123593023389696 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.06s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.06s\n",
            "I0208 17:35:28.362850 123593023389696 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.06s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.05s\n",
            "I0208 17:35:28.416858 123593023389696 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.05s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.02s\n",
            "I0208 17:35:28.433652 123593023389696 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I0208 17:35:28.532623 123593023389696 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I0208 17:35:28.532711 123593023389696 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 64\n",
            "I0208 17:35:28.532741 123593023389696 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 3\n",
            "I0208 17:35:28.534081 123593023389696 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0208 17:35:28.549865 123593023389696 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0208 17:35:28.549917 123593023389696 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0208 17:35:28.593010 123593023389696 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0208 17:35:28.593100 123593023389696 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0208 17:35:28.704525 123593023389696 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0208 17:35:28.704628 123593023389696 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0208 17:35:28.814753 123593023389696 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0208 17:35:28.814851 123593023389696 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0208 17:35:28.976390 123593023389696 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0208 17:35:28.976487 123593023389696 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0208 17:35:29.136723 123593023389696 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0208 17:35:29.136819 123593023389696 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0208 17:35:29.349881 123593023389696 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0208 17:35:29.349978 123593023389696 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I0208 17:35:29.403307 123593023389696 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I0208 17:35:29.427222 123593023389696 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0208 17:35:29.457803 123593023389696 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I0208 17:35:29.457892 123593023389696 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 88\n",
            "I0208 17:35:29.457923 123593023389696 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 4\n",
            "I0208 17:35:29.458979 123593023389696 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0208 17:35:29.468578 123593023389696 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0208 17:35:29.468630 123593023389696 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0208 17:35:29.547835 123593023389696 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0208 17:35:29.547930 123593023389696 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0208 17:35:29.692897 123593023389696 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0208 17:35:29.692996 123593023389696 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0208 17:35:29.836514 123593023389696 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0208 17:35:29.836614 123593023389696 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0208 17:35:30.025598 123593023389696 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0208 17:35:30.025701 123593023389696 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0208 17:35:30.215501 123593023389696 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0208 17:35:30.215599 123593023389696 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0208 17:35:30.451243 123593023389696 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0208 17:35:30.451339 123593023389696 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I0208 17:35:30.551063 123593023389696 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I0208 17:35:30.568199 123593023389696 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0208 17:35:30.604007 123593023389696 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I0208 17:35:30.604096 123593023389696 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 112\n",
            "I0208 17:35:30.604127 123593023389696 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 5\n",
            "I0208 17:35:30.605190 123593023389696 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0208 17:35:30.614926 123593023389696 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0208 17:35:30.614973 123593023389696 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0208 17:35:30.686985 123593023389696 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0208 17:35:30.687073 123593023389696 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0208 17:35:30.972518 123593023389696 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0208 17:35:30.972644 123593023389696 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0208 17:35:31.134848 123593023389696 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0208 17:35:31.134948 123593023389696 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I0208 17:35:31.349498 123593023389696 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I0208 17:35:31.349601 123593023389696 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I0208 17:35:31.567475 123593023389696 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I0208 17:35:31.567577 123593023389696 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I0208 17:35:31.840979 123593023389696 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I0208 17:35:31.841089 123593023389696 efficientnet_model.py:143] round_filter input=320 output=352\n",
            "I0208 17:35:31.953098 123593023389696 efficientnet_model.py:143] round_filter input=1280 output=1408\n",
            "I0208 17:35:31.975173 123593023389696 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0208 17:35:32.013123 123593023389696 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I0208 17:35:32.013227 123593023389696 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 160\n",
            "I0208 17:35:32.013270 123593023389696 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 6\n",
            "I0208 17:35:32.014435 123593023389696 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I0208 17:35:32.027622 123593023389696 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I0208 17:35:32.027688 123593023389696 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0208 17:35:32.118478 123593023389696 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0208 17:35:32.118575 123593023389696 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0208 17:35:32.303581 123593023389696 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0208 17:35:32.303687 123593023389696 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0208 17:35:32.448724 123593023389696 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0208 17:35:32.448826 123593023389696 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I0208 17:35:32.719363 123593023389696 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I0208 17:35:32.719462 123593023389696 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I0208 17:35:32.993728 123593023389696 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I0208 17:35:32.993832 123593023389696 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I0208 17:35:33.322077 123593023389696 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I0208 17:35:33.322182 123593023389696 efficientnet_model.py:143] round_filter input=320 output=384\n",
            "I0208 17:35:33.432518 123593023389696 efficientnet_model.py:143] round_filter input=1280 output=1536\n",
            "I0208 17:35:33.453722 123593023389696 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0208 17:35:33.492941 123593023389696 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I0208 17:35:33.493034 123593023389696 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 224\n",
            "I0208 17:35:33.493081 123593023389696 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 7\n",
            "I0208 17:35:33.494334 123593023389696 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0208 17:35:33.506844 123593023389696 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0208 17:35:33.506901 123593023389696 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0208 17:35:33.585522 123593023389696 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0208 17:35:33.585622 123593023389696 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0208 17:35:33.778582 123593023389696 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0208 17:35:33.778688 123593023389696 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I0208 17:35:33.991470 123593023389696 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I0208 17:35:33.991569 123593023389696 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I0208 17:35:34.316307 123593023389696 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I0208 17:35:34.316413 123593023389696 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I0208 17:35:34.645242 123593023389696 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I0208 17:35:34.645343 123593023389696 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I0208 17:35:35.081841 123593023389696 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I0208 17:35:35.081939 123593023389696 efficientnet_model.py:143] round_filter input=320 output=448\n",
            "I0208 17:35:35.192324 123593023389696 efficientnet_model.py:143] round_filter input=1280 output=1792\n",
            "I0208 17:35:35.213937 123593023389696 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0208 17:35:35.459959 123593023389696 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I0208 17:35:35.460058 123593023389696 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 288\n",
            "I0208 17:35:35.460089 123593023389696 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 7\n",
            "I0208 17:35:35.461277 123593023389696 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0208 17:35:35.471056 123593023389696 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0208 17:35:35.471101 123593023389696 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0208 17:35:35.591374 123593023389696 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0208 17:35:35.591472 123593023389696 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0208 17:35:35.861215 123593023389696 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0208 17:35:35.861314 123593023389696 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I0208 17:35:36.129073 123593023389696 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I0208 17:35:36.129172 123593023389696 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I0208 17:35:36.499960 123593023389696 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I0208 17:35:36.500061 123593023389696 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I0208 17:35:36.880641 123593023389696 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I0208 17:35:36.880741 123593023389696 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I0208 17:35:37.368076 123593023389696 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I0208 17:35:37.368176 123593023389696 efficientnet_model.py:143] round_filter input=320 output=512\n",
            "I0208 17:35:37.532420 123593023389696 efficientnet_model.py:143] round_filter input=1280 output=2048\n",
            "I0208 17:35:37.553879 123593023389696 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0208 17:35:37.604923 123593023389696 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I0208 17:35:37.605017 123593023389696 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 384\n",
            "I0208 17:35:37.605049 123593023389696 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 8\n",
            "I0208 17:35:37.606125 123593023389696 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I0208 17:35:37.618710 123593023389696 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I0208 17:35:37.618775 123593023389696 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0208 17:35:37.748009 123593023389696 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0208 17:35:37.748106 123593023389696 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0208 17:35:38.038088 123593023389696 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0208 17:35:38.038191 123593023389696 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I0208 17:35:38.359508 123593023389696 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I0208 17:35:38.359608 123593023389696 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I0208 17:35:38.787133 123593023389696 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I0208 17:35:38.787232 123593023389696 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I0208 17:35:39.217925 123593023389696 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I0208 17:35:39.218024 123593023389696 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I0208 17:35:39.816593 123593023389696 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I0208 17:35:39.816699 123593023389696 efficientnet_model.py:143] round_filter input=320 output=576\n",
            "I0208 17:35:39.979186 123593023389696 efficientnet_model.py:143] round_filter input=1280 output=2304\n",
            "I0208 17:35:40.000725 123593023389696 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0208 17:35:40.290703 123593023389696 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I0208 17:35:40.290800 123593023389696 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 384\n",
            "I0208 17:35:40.290831 123593023389696 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 8\n",
            "I0208 17:35:40.291903 123593023389696 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I0208 17:35:40.304692 123593023389696 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I0208 17:35:40.304745 123593023389696 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0208 17:35:40.468663 123593023389696 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0208 17:35:40.468763 123593023389696 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I0208 17:35:40.851228 123593023389696 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I0208 17:35:40.851329 123593023389696 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I0208 17:35:41.234871 123593023389696 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I0208 17:35:41.234972 123593023389696 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I0208 17:35:41.770492 123593023389696 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I0208 17:35:41.770594 123593023389696 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I0208 17:35:42.321882 123593023389696 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I0208 17:35:42.321981 123593023389696 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I0208 17:35:43.031079 123593023389696 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I0208 17:35:43.031179 123593023389696 efficientnet_model.py:143] round_filter input=320 output=640\n",
            "I0208 17:35:43.250871 123593023389696 efficientnet_model.py:143] round_filter input=1280 output=2560\n",
            "I0208 17:35:43.273095 123593023389696 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 14.91s\n",
            "I0208 17:35:43.341893 123593023389696 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 14.91s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.01s\n",
            "I0208 17:35:43.443534 123593023389696 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.01s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I0208 17:35:43.444533 123593023389696 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I0208 17:35:43.444742 123593023389696 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I0208 17:35:43.445440 123593023389696 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I0208 17:35:43.446079 123593023389696 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I0208 17:35:43.446248 123593023389696 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I0208 17:35:43.446732 123593023389696 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 24 tests in 17.948s\n",
            "\n",
            "OK (skipped=1)\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!python3 {HOMEFOLDER}models/research/object_detection/builders/model_builder_tf2_test.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmROIG9zaS9G"
      },
      "source": [
        "# 1.1. Get Dataset From Google Drive\n",
        "\n",
        "1. Expand this section\n",
        "2. Upload your RoboFlow .tfrecord.zip to Google Drive\n",
        "3. Share the uploaded .tfrecord.zip such that anyone with the link can access the file.\n",
        "4. Run this block\n",
        "5. Paste your Google Drive file share link into the text box that appears after running this block\n",
        "6. Click the \"Process Dataset\" Buttton\n",
        "7. Click the Refresh button in the \"Files\" pane to ensure dataset.zip exists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLgAPsQsfTLs"
      },
      "outputs": [],
      "source": [
        "import gdown\n",
        "import os\n",
        "from IPython.display import display\n",
        "from ipywidgets import Text, Button, VBox\n",
        "\n",
        "def process_dataset():\n",
        "    link_input = Text(\n",
        "        value='',\n",
        "        placeholder='Paste your Google Drive share link here',\n",
        "        description='Drive Link:',\n",
        "        style={'description_width': 'initial'},\n",
        "        layout={'width': '50%'}\n",
        "    )\n",
        "\n",
        "    def on_click(b):\n",
        "        try:\n",
        "            print(\"Downloading dataset...\")\n",
        "            url = link_input.value\n",
        "\n",
        "            # Convert share URL to direct download URL if needed\n",
        "            if 'drive.google.com/file/d/' in url:\n",
        "                file_id = url.split('/file/d/')[1].split('/')[0]\n",
        "                url = f'https://drive.google.com/uc?id={file_id}'\n",
        "\n",
        "            output = '/content/dataset.zip'\n",
        "            gdown.download(url, output, fuzzy=True)\n",
        "            print(\"Download complete!\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {str(e)}\")\n",
        "\n",
        "    process_button = Button(description='Process Dataset', button_style='primary')\n",
        "    process_button.on_click(on_click)\n",
        "    display(VBox([link_input, process_button]))\n",
        "\n",
        "# Install gdown if not already installed\n",
        "!pip install -q gdown --upgrade\n",
        "\n",
        "# Execute\n",
        "process_dataset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6kMXxVJo5za"
      },
      "source": [
        "# 2. Auto-detect relevant tfrecord components"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "WoA8HHf3I2t1",
        "outputId": "a3342d57-90e5-48ab-a9b9-47cd038822c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/home/atharv/dataset.zip\n",
            "Archive:  /home/atharv/dataset.zip\n",
            "replace README.dataset.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
          ]
        }
      ],
      "source": [
        "datasetPath = '/home/atharv/dataset.zip'\n",
        "print(datasetPath)\n",
        "!unzip $datasetPath"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "YUd2wtfrqedy",
        "outputId": "8cc57a83-ecd0-417e-c462-288980484473",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Record File: /home/atharv/train/coral-and-algae.tfrecord\n",
            "Validation Record File: /home/atharv/valid/coral-and-algae.tfrecord\n",
            "Label Map File: /home/atharv/train/coral-and-algae_label_map.pbtxt\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import fnmatch\n",
        "\n",
        "def find_files(directory, pattern):\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for basename in files:\n",
        "            if fnmatch.fnmatch(basename, pattern):\n",
        "                filename = os.path.join(root, basename)\n",
        "                yield filename\n",
        "\n",
        "def set_tfrecord_variables(directory):\n",
        "    train_record_fname = ''\n",
        "    val_record_fname = ''\n",
        "    label_map_pbtxt_fname = ''\n",
        "\n",
        "    for tfrecord_file in find_files(directory, '*.tfrecord'):\n",
        "        if '/train/' in tfrecord_file:\n",
        "            train_record_fname = tfrecord_file\n",
        "        elif '/valid/' in tfrecord_file:\n",
        "            val_record_fname = tfrecord_file\n",
        "        elif '/test/' in tfrecord_file:\n",
        "            pass\n",
        "\n",
        "    for label_map_file in find_files(directory, '*_label_map.pbtxt'):\n",
        "        label_map_pbtxt_fname = label_map_file  # Assuming one common label map file\n",
        "\n",
        "    return train_record_fname, val_record_fname, label_map_pbtxt_fname\n",
        "\n",
        "\n",
        "train_record_fname, val_record_fname, label_map_pbtxt_fname = set_tfrecord_variables('/home/atharv')\n",
        "\n",
        "train_record_fname = '/home/atharv/train/coral-and-algae.tfrecord'\n",
        "val_record_fname = '/home/atharv/valid/coral-and-algae.tfrecord'\n",
        "label_map_pbtxt_fname = '/home/atharv/train/coral-and-algae_label_map.pbtxt'\n",
        "\n",
        "#if(MLENVIRONMENT==\"COLAB\"):\n",
        "    #train_record_fname = '/content/train/cubes-cones.tfrecord'\n",
        "    #val_record_fname = '/content/valid/cubes-cones.tfrecord'\n",
        "    #label_map_pbtxt_fname = '/content/train/cubes-cones_label_map.pbtxt'\n",
        "\n",
        "print(\"Train Record File:\", train_record_fname)\n",
        "print(\"Validation Record File:\", val_record_fname)\n",
        "print(\"Label Map File:\", label_map_pbtxt_fname)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGEUZYAMEZ6f"
      },
      "source": [
        "# 3.&nbsp;Training Configuration and Labels File Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2MAcgJ53STW"
      },
      "source": [
        "Download the pre-trained Limelight Base Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "gN0EUEa3e5Un",
        "outputId": "69e0106b-db47-436c-a4bb-165df5ae7837",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/home/atharv\n",
            "mkdir: cannot create directory â€˜/home/atharv/models/mymodel/â€™: File exists\n",
            "/home/atharv/models/mymodel\n",
            "--2025-02-08 17:33:22--  https://downloads.limelightvision.io/models/limelight_ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz\n",
            "Resolving downloads.limelightvision.io (downloads.limelightvision.io)... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/atharv/.local/lib/python3.10/site-packages/IPython/core/magics/osm.py:393: UserWarning: This is now an optional IPython functionality, using bookmarks requires you to install the `pickleshare` library.\n",
            "  bkms = self.shell.db.get('bookmarks', {})\n",
            "/home/atharv/.local/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
            "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2600:9000:20ed:e800:c:efbc:d340:93a1, 2600:9000:20ed:7200:c:efbc:d340:93a1, 2600:9000:20ed:600:c:efbc:d340:93a1, ...\n",
            "Connecting to downloads.limelightvision.io (downloads.limelightvision.io)|2600:9000:20ed:e800:c:efbc:d340:93a1|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 46042990 (44M) [application/x-gzip]\n",
            "Saving to: â€˜limelight_ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz.2â€™\n",
            "\n",
            "limelight_ssd_mobil 100%[===================>]  43.91M  5.92MB/s    in 8.5s    \n",
            "\n",
            "2025-02-08 17:33:31 (5.14 MB/s) - â€˜limelight_ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz.2â€™ saved [46042990/46042990]\n",
            "\n",
            "--2025-02-08 17:33:32--  https://downloads.limelightvision.io/models/limelight_ssd_mobilenet_v2_320x320_coco17_tpu-8.config\n",
            "Resolving downloads.limelightvision.io (downloads.limelightvision.io)... 2600:9000:20ed:7c00:c:efbc:d340:93a1, 2600:9000:20ed:e800:c:efbc:d340:93a1, 2600:9000:20ed:7200:c:efbc:d340:93a1, ...\n",
            "Connecting to downloads.limelightvision.io (downloads.limelightvision.io)|2600:9000:20ed:7c00:c:efbc:d340:93a1|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4681 (4.6K) [binary/octet-stream]\n",
            "Saving to: â€˜limelight_ssd_mobilenet_v2_320x320_coco17_tpu-8.config.2â€™\n",
            "\n",
            "limelight_ssd_mobil 100%[===================>]   4.57K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2025-02-08 17:33:32 (5.51 MB/s) - â€˜limelight_ssd_mobilenet_v2_320x320_coco17_tpu-8.config.2â€™ saved [4681/4681]\n",
            "\n",
            "/home/atharv\n"
          ]
        }
      ],
      "source": [
        "chosen_model = 'ssd-mobilenet-v2'\n",
        "MODELS_CONFIG = {\n",
        "    'ssd-mobilenet-v2': {\n",
        "        'model_name': 'ssd_mobilenet_v2_320x320_coco17_tpu-8',\n",
        "        'base_pipeline_file': 'limelight_ssd_mobilenet_v2_320x320_coco17_tpu-8.config',\n",
        "        'pretrained_checkpoint': 'limelight_ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz',\n",
        "    },\n",
        "}\n",
        "model_name = MODELS_CONFIG[chosen_model]['model_name']\n",
        "pretrained_checkpoint = MODELS_CONFIG[chosen_model]['pretrained_checkpoint']\n",
        "base_pipeline_file = MODELS_CONFIG[chosen_model]['base_pipeline_file']\n",
        "\n",
        "# Create \"mymodel\" folder for pre-trained weights and configuration files\n",
        "%cd ~\n",
        "%mkdir {HOMEFOLDER}models/mymodel/\n",
        "%cd {HOMEFOLDER}models/mymodel/\n",
        "%pwd\n",
        "\n",
        "# Download pre-trained model weights\n",
        "import tarfile\n",
        "download_tar = 'https://downloads.limelightvision.io/models/' + pretrained_checkpoint\n",
        "!wget {download_tar}\n",
        "tar = tarfile.open(pretrained_checkpoint)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "# Download training configuration file for model\n",
        "download_config = 'https://downloads.limelightvision.io/models/' + base_pipeline_file\n",
        "!wget {download_config}\n",
        "%cd ~\n",
        "\n",
        "# Set training parameters for the model\n",
        "num_steps = 40000\n",
        "checkpoint_every = 2000\n",
        "batch_size = 16\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMbr89qqgTVW"
      },
      "source": [
        "Generate Labels File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "DDyH_i3MgP1D",
        "outputId": "363f71eb-f7ad-4ffd-8065-450907367dfc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-02-08 17:33:36.559636: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-02-08 17:33:36.559664: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-02-08 17:33:36.560514: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-08 17:33:36.565262: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-02-08 17:33:37.242990: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total classes: 2\n",
            "['ALGAE', 'CORAL']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Set file locations and get number of classes for config file\n",
        "pipeline_fname = HOMEFOLDER+'models/mymodel/' + base_pipeline_file\n",
        "fine_tune_checkpoint = HOMEFOLDER+'models/mymodel/' + model_name + '/checkpoint/ckpt-0'\n",
        "\n",
        "def get_num_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=90, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "    return len(category_index.keys())\n",
        "\n",
        "def get_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=90, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "\n",
        "    class_names = [category['name'] for category in category_index.values()]\n",
        "    return class_names\n",
        "\n",
        "def create_label_file(filename, labels):\n",
        "    with open(filename, 'w') as file:\n",
        "        for label in labels:\n",
        "            file.write(label + '\\n')\n",
        "\n",
        "\n",
        "num_classes = get_num_classes(label_map_pbtxt_fname)\n",
        "classes = get_classes(label_map_pbtxt_fname)\n",
        "\n",
        "print('Total classes:', num_classes)\n",
        "print(classes)\n",
        "\n",
        "\n",
        "#Generate labels file\n",
        "create_label_file(HOMEFOLDER + \"limelight_neural_detector_labels.txt\", classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwPyaIAXxyKu"
      },
      "source": [
        "Modify the base Limelight Model Configuration File\n",
        "\n",
        "Augmentation Options: https://github.com/tensorflow/models/blob/master/research/object_detection/protos/preprocessor.proto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "5eA5ht3_yukT",
        "outputId": "9eb4369c-219a-48ff-dd08-c1291330c7d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "writing custom configuration file\n",
            " \n",
            "/home/atharv/training_progress/\n"
          ]
        }
      ],
      "source": [
        "# Create custom configuration file by writing the dataset, model checkpoint, and training parameters into the base pipeline file\n",
        "import re\n",
        "\n",
        "print('writing custom configuration file')\n",
        "\n",
        "\n",
        "\n",
        "with open(pipeline_fname) as f:\n",
        "    s = f.read()\n",
        "with open('pipeline_file.config', 'w') as f:\n",
        "\n",
        "    # Set fine_tune_checkpoint path\n",
        "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
        "\n",
        "    # Set tfrecord files for train and test datasets\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', 'input_path: \"{}\"'.format(val_record_fname), s)\n",
        "\n",
        "    # Set label_map_path\n",
        "    s = re.sub(\n",
        "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
        "\n",
        "    # Set batch_size\n",
        "    s = re.sub('batch_size: [0-9]+',\n",
        "               'batch_size: {}'.format(batch_size), s)\n",
        "\n",
        "    # Set training steps, num_steps\n",
        "    s = re.sub('num_steps: [0-9]+',\n",
        "               'num_steps: {}'.format(num_steps), s)\n",
        "\n",
        "    # Set number of classes num_classes\n",
        "    s = re.sub('checkpoint_every_n: [0-9]+',\n",
        "               'num_classes: {}'.format(num_classes), s)\n",
        "\n",
        "    # Change fine-tune checkpoint type from \"classification\" to \"detection\"\n",
        "    s = re.sub(\n",
        "        'fine_tune_checkpoint_type: \"classification\"', 'fine_tune_checkpoint_type: \"{}\"'.format('detection'), s)\n",
        "\n",
        "    # If using ssd-mobilenet-v2, reduce learning rate\n",
        "    if chosen_model == 'ssd-mobilenet-v2':\n",
        "      s = re.sub('learning_rate_base: .8',\n",
        "                 'learning_rate_base: .004', s)\n",
        "\n",
        "      s = re.sub('warmup_learning_rate: 0.13333',\n",
        "                 'warmup_learning_rate: .0016666', s)\n",
        "\n",
        "    # If using efficientdet-d0, use fixed_shape_resizer instead of keep_aspect_ratio_resizer (because it isn't supported by TFLite)\n",
        "    if chosen_model == 'efficientdet-d0':\n",
        "      s = re.sub('keep_aspect_ratio_resizer', 'fixed_shape_resizer', s)\n",
        "      s = re.sub('pad_to_max_dimension: true', '', s)\n",
        "      s = re.sub('min_dimension', 'height', s)\n",
        "      s = re.sub('max_dimension', 'width', s)\n",
        "\n",
        "    f.write(s)\n",
        "\n",
        "# (Optional) Display the custom configuration file's contents\n",
        "# !cat pipeline_file.config\n",
        "# Set the path to the custom config file and the directory to store training checkpoints in\n",
        "pipeline_file = 'pipeline_file.config'\n",
        "model_dir = HOMEFOLDER+'training_progress/'\n",
        "print(\" \")\n",
        "print(model_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-19zML6oEO7l"
      },
      "source": [
        "# 4.&nbsp;Train Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxPj_QV43qD5"
      },
      "source": [
        "Once training starts, come back and click the refresh button within the tensorboard window to check training progress.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TI9iCCxoNlAL"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir '/content/training_progress/train'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejo07C1zXHzY"
      },
      "source": [
        "Fix TF 2.15 breaking changes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Ltvi224axv3Y",
        "outputId": "2b56bcde-aa05-49b6-e2c1-4c76060d119d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File /home/atharv/.local/lib/python3.10/site-packages/tf_slim/data/tfexample_decoder.py fixed.\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "import re\n",
        "\n",
        "original_path = '/home/atharv/.local/lib/python3.10/site-packages/tf_slim/data/tfexample_decoder.py'\n",
        "with open(original_path, 'r') as file:\n",
        "  content = file.read()\n",
        "  content = re.sub(r'import abc', 'import tensorflow as tf\\n\\nimport abc', content)\n",
        "  content = re.sub(r'control_flow_ops.case', 'tf.case', content)\n",
        "  content = re.sub(r'control_flow_ops.cond', 'tf.compat.v1.cond', content)\n",
        "with open(original_path, 'w') as file:\n",
        "  file.write(content)\n",
        "\n",
        "print(f\"File {original_path} fixed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjqYo9r9ffVx"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "tQTfZChVzzpZ",
        "outputId": "078b275d-c73a-43d6-db3b-f6d6eddac944",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-02-08 17:36:02.007450: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
            "2025-02-08 17:36:02.007483: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
            "2025-02-08 17:36:02.008388: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
            "2025-02-08 17:36:02.012604: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\r\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-02-08 17:36:02.593053: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "WARNING:tensorflow:From /home/atharv/models/research/object_detection/model_main_tf2.py:100: _CollectiveAllReduceStrategyExperimental.__init__ (from tensorflow.python.distribute.collective_all_reduce_strategy) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "use distribute.MultiWorkerMirroredStrategy instead\n",
            "W0208 17:36:03.918577 139743728521216 deprecation.py:50] From /home/atharv/models/research/object_detection/model_main_tf2.py:100: _CollectiveAllReduceStrategyExperimental.__init__ (from tensorflow.python.distribute.collective_all_reduce_strategy) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "use distribute.MultiWorkerMirroredStrategy instead\n",
            "2025-02-08 17:36:04.046726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9970 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:0b:00.0, compute capability: 8.6\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/device:GPU:0',)\n",
            "I0208 17:36:04.170573 139743728521216 mirrored_strategy.py:423] Using MirroredStrategy with devices ('/device:GPU:0',)\n",
            "INFO:tensorflow:Single-worker MultiWorkerMirroredStrategy with local_devices = ('/device:GPU:0',), communication = CommunicationImplementation.AUTO\n",
            "I0208 17:36:04.170732 139743728521216 collective_all_reduce_strategy.py:446] Single-worker MultiWorkerMirroredStrategy with local_devices = ('/device:GPU:0',), communication = CommunicationImplementation.AUTO\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 40000\n",
            "I0208 17:36:04.172718 139743728521216 config_util.py:552] Maybe overwriting train_steps: 40000\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0208 17:36:04.172769 139743728521216 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "WARNING:tensorflow:From /home/atharv/.local/lib/python3.10/site-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W0208 17:36:04.195022 139743728521216 deprecation.py:50] From /home/atharv/.local/lib/python3.10/site-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/home/atharv/train/coral-and-algae.tfrecord']\n",
            "I0208 17:36:04.198528 139743728521216 dataset_builder.py:162] Reading unweighted datasets: ['/home/atharv/train/coral-and-algae.tfrecord']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/home/atharv/train/coral-and-algae.tfrecord']\n",
            "I0208 17:36:04.198598 139743728521216 dataset_builder.py:79] Reading record datasets for input file: ['/home/atharv/train/coral-and-algae.tfrecord']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0208 17:36:04.198641 139743728521216 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0208 17:36:04.198673 139743728521216 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /home/atharv/.local/lib/python3.10/site-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W0208 17:36:04.201948 139743728521216 deprecation.py:50] From /home/atharv/.local/lib/python3.10/site-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /home/atharv/.local/lib/python3.10/site-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0208 17:36:04.211721 139743728521216 deprecation.py:50] From /home/atharv/.local/lib/python3.10/site-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /home/atharv/.local/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1260: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0208 17:36:07.751312 139743728521216 deprecation.py:50] From /home/atharv/.local/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1260: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /home/atharv/.local/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1260: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0208 17:36:09.540257 139743728521216 deprecation.py:50] From /home/atharv/.local/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1260: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /home/atharv/.local/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1260: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0208 17:36:10.830663 139743728521216 deprecation.py:50] From /home/atharv/.local/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1260: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "/home/atharv/.local/lib/python3.10/site-packages/keras/src/backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn(\n",
            "I0208 17:36:15.290236 139736758879808 api.py:460] feature_map_spatial_dims: [(19, 19), (10, 10), (5, 5), (3, 3), (2, 2), (1, 1)]\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0208 17:36:16.079526 139736758879808 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0208 17:36:16.079698 139736758879808 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0208 17:36:16.079756 139736758879808 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0208 17:36:16.079808 139736758879808 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0208 17:36:16.079857 139736758879808 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0208 17:36:16.079912 139736758879808 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\n",
            "I0208 17:36:20.036574 139736758879808 api.py:460] feature_map_spatial_dims: [(19, 19), (10, 10), (5, 5), (3, 3), (2, 2), (1, 1)]\n",
            "2025-02-08 17:36:23.712785: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:447] Loaded runtime CuDNN library: 8.2.4 but source was compiled with: 8.9.4.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
            "2025-02-08 17:36:23.713472: W tensorflow/core/framework/op_kernel.cc:1839] OP_REQUIRES failed at conv_ops_impl.h:1199 : UNIMPLEMENTED: DNN library is not found.\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/atharv/models/research/object_detection/model_main_tf2.py\", line 114, in <module>\n",
            "    tf.compat.v1.app.run()\n",
            "  File \"/home/atharv/.local/lib/python3.10/site-packages/tensorflow/python/platform/app.py\", line 36, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"/home/atharv/.local/lib/python3.10/site-packages/absl/app.py\", line 308, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/home/atharv/.local/lib/python3.10/site-packages/absl/app.py\", line 254, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"/home/atharv/models/research/object_detection/model_main_tf2.py\", line 105, in main\n",
            "    model_lib_v2.train_loop(\n",
            "  File \"/home/atharv/.local/lib/python3.10/site-packages/object_detection/model_lib_v2.py\", line 605, in train_loop\n",
            "    load_fine_tune_checkpoint(\n",
            "  File \"/home/atharv/.local/lib/python3.10/site-packages/object_detection/model_lib_v2.py\", line 401, in load_fine_tune_checkpoint\n",
            "    _ensure_model_is_built(model, input_dataset, unpad_groundtruth_tensors)\n",
            "  File \"/home/atharv/.local/lib/python3.10/site-packages/object_detection/model_lib_v2.py\", line 176, in _ensure_model_is_built\n",
            "    strategy.run(\n",
            "  File \"/home/atharv/.local/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py\", line 1681, in run\n",
            "    return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n",
            "  File \"/home/atharv/.local/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py\", line 3271, in call_for_each_replica\n",
            "    return self._call_for_each_replica(fn, args, kwargs)\n",
            "  File \"/home/atharv/.local/lib/python3.10/site-packages/tensorflow/python/distribute/mirrored_strategy.py\", line 700, in _call_for_each_replica\n",
            "    return mirrored_run.call_for_each_replica(\n",
            "  File \"/home/atharv/.local/lib/python3.10/site-packages/tensorflow/python/distribute/mirrored_run.py\", line 84, in call_for_each_replica\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/home/atharv/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/home/atharv/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py\", line 53, in quick_execute\n",
            "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
            "tensorflow.python.framework.errors_impl.UnimplementedError: Graph execution error:\n",
            "\n",
            "Detected at node ssd_mobile_net_v2_keras_feature_extractor/model/Conv1/Conv2D defined at (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 973, in _bootstrap\n",
            "\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "\n",
            "  File \"/home/atharv/.local/lib/python3.10/site-packages/object_detection/model_lib_v2.py\", line 172, in _dummy_computation_fn\n",
            "\n",
            "  File \"/home/atharv/.local/lib/python3.10/site-packages/object_detection/model_lib_v2.py\", line 124, in _compute_losses_and_predictions_dicts\n",
            "\n",
            "  File \"/home/atharv/.local/lib/python3.10/site-packages/object_detection/meta_architectures/ssd_meta_arch.py\", line 570, in predict\n",
            "\n",
            "  File \"/home/atharv/.local/lib/python3.10/site-packages/object_detection/meta_architectures/ssd_meta_arch.py\", line 571, in predict\n",
            "\n",
            "  File \"/home/atharv/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n",
            "\n",
            "  File \"/home/atharv/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 590, in __call__\n",
            "\n",
            "  File \"/home/atharv/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n",
            "\n",
            "  File \"/home/atharv/.local/lib/python3.10/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n",
            "\n",
            "  File \"/home/atharv/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n",
            "\n",
            "  File \"/home/atharv/.local/lib/python3.10/site-packages/object_detection/meta_architectures/ssd_meta_arch.py\", line 252, in call\n",
            "\n",
            "  File \"/home/atharv/.local/lib/python3.10/site-packages/object_detection/models/ssd_mobilenet_v2_keras_feature_extractor.py\", line 160, in _extract_features\n",
            "\n",
            "  File \"/home/atharv/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n",
            "\n",
            "  File \"/home/atharv/.local/lib/python3.10/site-packages/keras/src/engine/training.py\", line 590, in __call__\n",
            "\n",
            "  File \"/home/atharv/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n",
            "\n",
            "  File \"/home/atharv/.local/lib/python3.10/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n",
            "\n",
            "  File \"/home/atharv/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n",
            "\n",
            "  File \"/home/atharv/.local/lib/python3.10/site-packages/keras/src/engine/functional.py\", line 515, in call\n",
            "\n",
            "  File \"/home/atharv/.local/lib/python3.10/site-packages/keras/src/engine/functional.py\", line 672, in _run_internal_graph\n",
            "\n",
            "  File \"/home/atharv/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n",
            "\n",
            "  File \"/home/atharv/.local/lib/python3.10/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n",
            "\n",
            "  File \"/home/atharv/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n",
            "\n",
            "  File \"/home/atharv/.local/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py\", line 290, in call\n",
            "\n",
            "  File \"/home/atharv/.local/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py\", line 262, in convolution_op\n",
            "\n",
            "DNN library is not found.\n",
            "\t [[{{node ssd_mobile_net_v2_keras_feature_extractor/model/Conv1/Conv2D}}]] [Op:__inference__dummy_computation_fn_21230]\n"
          ]
        }
      ],
      "source": [
        "!rm -rf {HOMEFOLDER}training_progress\n",
        "# Run training!\n",
        "!python3 {HOMEFOLDER}models/research/object_detection/model_main_tf2.py \\\n",
        "    --pipeline_config_path={pipeline_file} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\\n",
        "    --checkpoint_every_n={checkpoint_every} \\\n",
        "    --num_train_steps={num_steps} \\\n",
        "    --num_workers=2 \\\n",
        "    --sample_1_of_n_eval_examples=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHxbX4ZpzXIv"
      },
      "source": [
        "Feel free to stop training early. Check the 'training_progress' folder to see all training checkpoints.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPg8oMnQDYKl"
      },
      "source": [
        "# 5.&nbsp;Convert Model to TFLite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RaUU8tBlHifd"
      },
      "outputs": [],
      "source": [
        "#remove final output folder if it exists\n",
        "if os.path.exists(FINALOUTPUTFOLDER) and os.path.isdir(FINALOUTPUTFOLDER):\n",
        "  shutil.rmtree(FINALOUTPUTFOLDER)\n",
        "\n",
        "# Make a directory to store the trained TFLite model\n",
        "!mkdir {FINALOUTPUTFOLDER}\n",
        "print(FINALOUTPUTFOLDER)\n",
        "# Export graph\n",
        "# Path to training directory (the conversion script automatically chooses the highest checkpoint file)\n",
        "last_model_path = HOMEFOLDER+'training_progress'\n",
        "exporter_path = HOMEFOLDER+'models/research/object_detection/export_tflite_graph_tf2.py'\n",
        "output_directory = FINALOUTPUTFOLDER\n",
        "\n",
        "!python $exporter_path \\\n",
        "    --trained_checkpoint_dir $last_model_path \\\n",
        "    --output_directory $output_directory \\\n",
        "    --pipeline_config_path $pipeline_file\n",
        "\n",
        "# Convert to .tflite Flatbuffer\n",
        "import tensorflow as tf\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(FINALOUTPUTFOLDER+'/saved_model')\n",
        "tflite_model = converter.convert()\n",
        "model_path_32bit = FINALOUTPUTFOLDER+'/limelight_neural_detector_32bit.tflite'\n",
        "with open(model_path_32bit, 'wb') as f:\n",
        "  f.write(tflite_model)\n",
        "\n",
        "!cp {HOMEFOLDER}limelight_neural_detector_labels.txt {FINALOUTPUTFOLDER}\n",
        "!cp {HOMEFOLDER}models/mymodel/pipeline_file.config {FINALOUTPUTFOLDER}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqahbHU1suBi"
      },
      "outputs": [],
      "source": [
        "# Export graph\n",
        "# Path to training directory (the conversion script automatically chooses the highest checkpoint file)\n",
        "last_model_path = HOMEFOLDER+'training_progress'\n",
        "exporter_path = HOMEFOLDER+'models/research/object_detection/export_tflite_graph_tf2.py'\n",
        "output_directory = FINALOUTPUTFOLDER\n",
        "\n",
        "!python $exporter_path \\\n",
        "    --trained_checkpoint_dir $last_model_path \\\n",
        "    --output_directory $output_directory \\\n",
        "    --pipeline_config_path $pipeline_file\n",
        "\n",
        "# Convert to .tflite Flatbuffer\n",
        "import tensorflow as tf\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(FINALOUTPUTFOLDER+'/saved_model')\n",
        "tflite_model = converter.convert()\n",
        "model_path_32bit = FINALOUTPUTFOLDER+'/limelight_neural_detector_32bit.tflite'\n",
        "with open(model_path_32bit, 'wb') as f:\n",
        "  f.write(tflite_model)\n",
        "\n",
        "!cp {HOMEFOLDER}limelight_neural_detector_labels.txt {FINALOUTPUTFOLDER}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTyqlXFTJ0Uv"
      },
      "source": [
        "# 6. Quantize model\n",
        "The \"TFLiteConverter\" module will perform [post-training quantization](https://www.tensorflow.org/lite/performance/post_training_quantization) on the model. To quantize the model, we need to provide a set of example images. We will extract 100 images from the training tfrecord and place said images into the \"extracted_samples\" folder.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSNZtfj_k3NP"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import io\n",
        "from PIL import Image\n",
        "\n",
        "def extract_images_from_tfrecord(tfrecord_path, output_folder, num_samples=100):\n",
        "    # Make sure the output directory exists\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Initialize a counter for the number of images saved\n",
        "    saved_images = 0\n",
        "\n",
        "    # Read the TFRecord file\n",
        "    raw_dataset = tf.data.TFRecordDataset(tfrecord_path)\n",
        "    for raw_record in raw_dataset.take(num_samples):\n",
        "        example = tf.train.Example()\n",
        "        example.ParseFromString(raw_record.numpy())\n",
        "\n",
        "        # Extract the image data (change 'image/encoded' if necessary)\n",
        "        image_data = example.features.feature['image/encoded'].bytes_list.value[0]\n",
        "\n",
        "        # Decode the image data and save as a file\n",
        "        image = Image.open(io.BytesIO(image_data))\n",
        "        image.save(os.path.join(output_folder, f'image_{saved_images}.png'))\n",
        "\n",
        "        saved_images += 1\n",
        "        if saved_images >= num_samples:\n",
        "            break\n",
        "\n",
        "    print(f\"Extracted {saved_images} images to {output_folder}\")\n",
        "\n",
        "# Set the path to your TFRecord file and the output directory\n",
        "tfrecord_path = train_record_fname\n",
        "extracted_sample_folder = HOMEFOLDER+'extracted_samples'\n",
        "\n",
        "#remove sample folder if it exists\n",
        "if os.path.exists(extracted_sample_folder) and os.path.isdir(extracted_sample_folder):\n",
        "  shutil.rmtree(extracted_sample_folder)\n",
        "\n",
        "# Extract images\n",
        "extract_images_from_tfrecord(tfrecord_path, extracted_sample_folder)\n",
        "\n",
        "\n",
        "# Get list of all images in train directory\n",
        "from google.cloud import storage\n",
        "import glob\n",
        "\n",
        "quant_image_list=[]\n",
        "if(MLENVIRONMENT==\"COLAB\"):\n",
        "\n",
        "    jpg_file_list = glob.glob(extracted_sample_folder + '/*.jpg')\n",
        "    jpeg_file_list = glob.glob(extracted_sample_folder + '/*.jpeg')\n",
        "    JPG_file_list = glob.glob(extracted_sample_folder + '/*.JPG')\n",
        "    png_file_list = glob.glob(extracted_sample_folder + '/*.png')\n",
        "    bmp_file_list = glob.glob(extracted_sample_folder + '/*.bmp')\n",
        "    quant_image_list = jpg_file_list + JPG_file_list + png_file_list + bmp_file_list\n",
        "\n",
        "print(\"pulling samples from \" + extracted_sample_folder)\n",
        "print(\"samples: \" + str(len(quant_image_list)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORzx0XRErSLV"
      },
      "outputs": [],
      "source": [
        "# A generator that provides a representative dataset\n",
        "# Code modified from https://colab.research.google.com/github/google-coral/tutorials/blob/master/retrain_classification_ptq_tf2.ipynb\n",
        "\n",
        "# First, get input details for model so we know how to preprocess images\n",
        "interpreter = tf.lite.Interpreter(model_path=model_path_32bit)\n",
        "interpreter.allocate_tensors()\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "height = input_details[0]['shape'][1]\n",
        "width = input_details[0]['shape'][2]\n",
        "\n",
        "import random\n",
        "\n",
        "def representative_data_gen():\n",
        "  dataset_list = quant_image_list\n",
        "  quant_num = 300\n",
        "  for i in range(quant_num):\n",
        "    pick_me = random.choice(dataset_list)\n",
        "    print(pick_me)\n",
        "    image = tf.io.read_file(pick_me)\n",
        "\n",
        "    if pick_me.endswith('.jpg') or pick_me.endswith('.JPG') or pick_me.endswith('.jpeg'):\n",
        "      image = tf.io.decode_jpeg(image, channels=3)\n",
        "    elif pick_me.endswith('.png'):\n",
        "      image = tf.io.decode_png(image, channels=3)\n",
        "    elif pick_me.endswith('.bmp'):\n",
        "      image = tf.io.decode_bmp(image, channels=3)\n",
        "\n",
        "    image = tf.image.resize(image, [width, height])  # TO DO: Replace 300s with an automatic way of reading network input size\n",
        "    image = tf.cast(image / 255., tf.float32)\n",
        "    image = tf.expand_dims(image, 0)\n",
        "    yield [image]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqtu98mzebEj"
      },
      "source": [
        "Finally, we'll initialize the TFLiteConverter module, point it at the TFLite graph we generated in Step 6, and provide it with the representative dataset generator function we created in the previous code block. We'll configure the converter to quantize the model's weight values to INT8 format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ox0bGDWds_Ce"
      },
      "outputs": [],
      "source": [
        "# Initialize converter module\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(FINALOUTPUTFOLDER+'/saved_model')\n",
        "print(\"initialized converter\")\n",
        "# This enables quantization\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "# This sets the representative dataset for quantization\n",
        "converter.representative_dataset = representative_data_gen\n",
        "# This ensures that if any ops can't be quantized, the converter throws an error\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "# For full integer quantization, though supported types defaults to int8 only, we explicitly declare it for clarity.\n",
        "converter.target_spec.supported_types = [tf.int8]\n",
        "# These set the input tensors to uint8 and output tensors to float32\n",
        "converter.inference_input_type = tf.uint8\n",
        "converter.inference_output_type = tf.float32\n",
        "print(\"begin conversion\")\n",
        "tflite_model = converter.convert()\n",
        "print(\"conversion complete\")\n",
        "\n",
        "with open(FINALOUTPUTFOLDER+'/limelight_neural_detector_8bit.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFsuasvxFHo8"
      },
      "source": [
        "# 7. Compile Model for Limelight & Download\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peawOI_z0DHt"
      },
      "source": [
        "Install Coral Compiler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUd_SNC0JSq0"
      },
      "outputs": [],
      "source": [
        "! curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n",
        "! echo \"deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\" | sudo tee /etc/apt/sources.list.d/coral-edgetpu.list\n",
        "! sudo apt-get update\n",
        "! sudo apt-get install edgetpu-compiler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usfmdtSiJuuC"
      },
      "source": [
        "Compile the previously-generated 8-bit model for Google Coral"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mULCY0nb0ahH"
      },
      "outputs": [],
      "source": [
        "!cd {FINALOUTPUTFOLDER} && pwd && edgetpu_compiler limelight_neural_detector_8bit.tflite && pwd && mv limelight_neural_detector_8bit_edgetpu.tflite limelight_neural_detector_coral.tflite && rm limelight_neural_detector_8bit_edgetpu.log"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqGy2FgzKomN"
      },
      "source": [
        "Zip models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nCdUouYJjQM"
      },
      "outputs": [],
      "source": [
        "!rm {HOMEFOLDER}limelight_detectors.zip\n",
        "!zip -r {HOMEFOLDER}limelight_detectors.zip {FINALOUTPUTFOLDER}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHgbpkQue-ZR"
      },
      "source": [
        "Download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AmjqvKuuK8ZR"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download(HOMEFOLDER+'limelight_detectors.zip')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "05N8FeXHcQp3",
        "xmROIG9zaS9G",
        "eGEUZYAMEZ6f",
        "-19zML6oEO7l",
        "kPg8oMnQDYKl",
        "VTyqlXFTJ0Uv",
        "XFsuasvxFHo8"
      ],
      "gpuClass": "premium",
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "dac6b1a68a930bf8a24417228a96ab80b19f2aa97bc2d428affc356154b4740f"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}