{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Random-Coder-Dude/Realtime-Object-Detection/blob/main/limelight-detector-training-notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJVo_xMPf4LY"
      },
      "source": [
        "![TrainingNotebookLogo.png](https://downloads.limelightvision.io/content/TrainingNotebookLogo.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72xbzFQrPL5q"
      },
      "source": [
        "To train a neural object detector for Limelight, click the \"play\" button on each code block. Pay extra attention to any \"â—\" you see. By the end of this tutorial, you will have downloaded a .zip file containing your model and label files.\n",
        "\n",
        "See https://docs.limelightvision.io/docs/docs-limelight/pipeline-neural/training-your-own-detector for a more in-depth tutorial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05N8FeXHcQp3"
      },
      "source": [
        "# 1. Install The Object Detection Package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ypWGYdPlLRUN",
        "outputId": "cd2bbcb1-fb6c-4a6f-9fcd-91d9bbd067a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'models' already exists and is not an empty directory.\n",
            "remote: Enumerating objects: 3055, done.\u001b[K\n",
            "remote: Counting objects: 100% (3055/3055), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1359/1359), done.\u001b[K\n",
            "remote: Total 1824 (delta 1223), reused 703 (delta 446), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (1824/1824), 10.05 MiB | 9.41 MiB/s, done.\n",
            "Resolving deltas: 100% (1223/1223), completed with 739 local objects.\n",
            "From https://github.com/tensorflow/models\n",
            " * branch            ad1f7b56943998864db8f5db0706950e93bb7d81 -> FETCH_HEAD\n",
            "HEAD is now at ad1f7b5 adjust folder path\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: protobuf==3.20.3 in ./.local/lib/python3.10/site-packages (3.20.3)\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "import os\n",
        "tmpModelPath ='/content/models'\n",
        "if os.path.exists(tmpModelPath) and os.path.isdir(tmpModelPath):\n",
        "  shutil.rmtree(tmpModelPath)\n",
        "\n",
        "MLENVIRONMENT=\"COLAB\"\n",
        "!git clone --depth 1 https://github.com/tensorflow/models\n",
        "!cd models && git fetch --depth 1 origin ad1f7b56943998864db8f5db0706950e93bb7d81 && git checkout ad1f7b56943998864db8f5db0706950e93bb7d81\n",
        "!pip install protobuf==3.20.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6QPmVBSlLTzM",
        "outputId": "544fe84b-4961-4ea5-fcc8-7b90e7c92477",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.10.12 (main, Jan 17 2025, 14:35:34) [GCC 11.4.0]\n",
            "colab env setup\n",
            "/home/atharv/\n",
            "/home/atharv/models/research\r\n"
          ]
        }
      ],
      "source": [
        "# Environment Setup\n",
        "import os\n",
        "import sys\n",
        "import re\n",
        "\n",
        "print(sys.version)\n",
        "if(MLENVIRONMENT == \"COLAB\"):\n",
        "    print(\"colab env setup\")\n",
        "    os.environ[\"HOMEFOLDER\"] = \"/home/atharv/\"\n",
        "    HOMEFOLDER = '{HOMEFOLDER}'.format(**os.environ)\n",
        "    FINALOUTPUTFOLDER_DIRNAME = 'final_output'\n",
        "    FINALOUTPUTFOLDER = HOMEFOLDER+FINALOUTPUTFOLDER_DIRNAME\n",
        "    print(HOMEFOLDER)\n",
        "\n",
        "# Copy setup files into models/research folder\n",
        "!cd {HOMEFOLDER}models/research && pwd && protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "# Modify setup.py\n",
        "with open(HOMEFOLDER+'models/research/object_detection/packages/tf2/setup.py') as f:\n",
        "    s = f.read()\n",
        "\n",
        "with open(HOMEFOLDER+'models/research/setup.py', 'w') as f:\n",
        "    if(MLENVIRONMENT == \"COLAB\"):\n",
        "        s = re.sub('tf-models-official>=2.5.1','tf-models-official==2.15.0', s)\n",
        "        f.write(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OLDnCkLLwLr6",
        "outputId": "ada79a6d-7392-4249-8a1b-acab6d67ab90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Processing ./models/research\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25hCollecting Cython\n",
            "  Using cached Cython-3.0.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "Collecting apache-beam\n",
            "  Using cached apache_beam-2.62.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.1 MB)\n",
            "Collecting avro-python3\n",
            "  Using cached avro_python3-1.10.2-py3-none-any.whl\n",
            "Collecting contextlib2\n",
            "  Using cached contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: keras in ./.local/lib/python3.10/site-packages (from object-detection==0.1) (2.15.0)\n",
            "Collecting lvis\n",
            "  Using cached lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Collecting lxml\n",
            "  Using cached lxml-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (5.0 MB)\n",
            "Collecting matplotlib\n",
            "  Using cached matplotlib-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "Collecting pandas\n",
            "  Using cached pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "Requirement already satisfied: pillow in /usr/lib/python3/dist-packages (from object-detection==0.1) (9.0.1)\n",
            "Collecting pycocotools\n",
            "  Using cached pycocotools-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (427 kB)\n",
            "Requirement already satisfied: pyparsing==2.4.7 in /usr/lib/python3/dist-packages (from object-detection==0.1) (2.4.7)\n",
            "Collecting sacrebleu<=2.2.0\n",
            "  Using cached sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n",
            "Collecting scipy\n",
            "  Using cached scipy-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (40.6 MB)\n",
            "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from object-detection==0.1) (1.16.0)\n",
            "Collecting tensorflow_io\n",
            "  Using cached tensorflow_io-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.6 MB)\n",
            "Collecting tf-models-official==2.15.0\n",
            "  Using cached tf_models_official-2.15.0-py2.py3-none-any.whl (2.7 MB)\n",
            "Collecting tf-slim\n",
            "  Using cached tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "Collecting google-api-python-client>=1.6.7\n",
            "  Using cached google_api_python_client-2.160.0-py2.py3-none-any.whl (12.8 MB)\n",
            "Collecting pyyaml>=6.0.0\n",
            "  Using cached PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (751 kB)\n",
            "Collecting immutabledict\n",
            "  Using cached immutabledict-4.2.1-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: numpy>=1.20 in ./.local/lib/python3.10/site-packages (from tf-models-official==2.15.0->object-detection==0.1) (1.26.4)\n",
            "Collecting oauth2client\n",
            "  Using cached oauth2client-4.1.3-py2.py3-none-any.whl (98 kB)\n",
            "Requirement already satisfied: tensorflow~=2.15.0 in ./.local/lib/python3.10/site-packages (from tf-models-official==2.15.0->object-detection==0.1) (2.15.0)\n",
            "Collecting gin-config\n",
            "  Using cached gin_config-0.5.0-py3-none-any.whl (61 kB)\n",
            "Collecting kaggle>=1.3.9\n",
            "  Using cached kaggle-1.6.17-py3-none-any.whl\n",
            "Collecting tensorflow-model-optimization>=0.4.1\n",
            "  Using cached tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl (242 kB)\n",
            "Collecting tensorflow-hub>=0.6.0\n",
            "  Using cached tensorflow_hub-0.16.1-py2.py3-none-any.whl (30 kB)\n",
            "Collecting opencv-python-headless\n",
            "  Using cached opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50.0 MB)\n",
            "Collecting sentencepiece\n",
            "  Using cached sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "Collecting py-cpuinfo>=3.3.0\n",
            "  Using cached py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: psutil>=5.4.3 in ./.local/lib/python3.10/site-packages (from tf-models-official==2.15.0->object-detection==0.1) (6.1.1)\n",
            "Collecting seqeval\n",
            "  Using cached seqeval-1.2.2-py3-none-any.whl\n",
            "Collecting tensorflow-datasets\n",
            "  Using cached tensorflow_datasets-4.9.7-py3-none-any.whl (5.3 MB)\n",
            "Collecting tensorflow-text~=2.15.0\n",
            "  Using cached tensorflow_text-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in ./.local/lib/python3.10/site-packages (from pandas->object-detection==0.1) (2.9.0.post0)\n",
            "Collecting tzdata>=2022.7\n",
            "  Using cached tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->object-detection==0.1) (2022.1)\n",
            "Requirement already satisfied: colorama in /usr/lib/python3/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (0.4.4)\n",
            "Collecting regex\n",
            "  Using cached regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
            "Collecting tabulate>=0.8.9\n",
            "  Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
            "Collecting portalocker\n",
            "  Using cached portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in ./.local/lib/python3.10/site-packages (from tf-slim->object-detection==0.1) (2.1.0)\n",
            "Collecting grpcio!=1.48.0,!=1.59.*,!=1.60.*,!=1.61.*,!=1.62.0,!=1.62.1,<1.66.0,<2,>=1.33.1\n",
            "  Using cached grpcio-1.65.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.7 MB)\n",
            "Collecting jsonpickle<4.0.0,>=3.0.0\n",
            "  Using cached jsonpickle-3.4.2-py3-none-any.whl (46 kB)\n",
            "Collecting redis<6,>=5.0.0\n",
            "  Using cached redis-5.2.1-py3-none-any.whl (261 kB)\n",
            "Collecting cloudpickle~=2.2.1\n",
            "  Using cached cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.0 in ./.local/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (4.12.2)\n",
            "Collecting hdfs<3.0.0,>=2.1.0\n",
            "  Using cached hdfs-2.7.3-py3-none-any.whl\n",
            "Requirement already satisfied: requests<3.0.0,>=2.24.0 in ./.local/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (2.32.3)\n",
            "Collecting fasteners<1.0,>=0.3\n",
            "  Using cached fasteners-0.19-py3-none-any.whl (18 kB)\n",
            "Collecting dill<0.3.2,>=0.3.1.1\n",
            "  Using cached dill-0.3.1.1-py3-none-any.whl\n",
            "Collecting fastavro<2,>=0.23.6\n",
            "  Using cached fastavro-1.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "Collecting sortedcontainers>=2.4.0\n",
            "  Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: packaging>=22.0 in ./.local/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (24.2)\n",
            "Collecting orjson<4,>=3.9.7\n",
            "  Using cached orjson-3.10.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in ./.local/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (4.23.0)\n",
            "Requirement already satisfied: httplib2<0.23.0,>=0.8 in /usr/lib/python3/dist-packages (from apache-beam->object-detection==0.1) (0.20.2)\n",
            "Collecting pyarrow-hotfix<1\n",
            "  Using cached pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Collecting zstandard<1,>=0.18.0\n",
            "  Using cached zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "Collecting pymongo<5.0.0,>=3.8.0\n",
            "  Using cached pymongo-4.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "Requirement already satisfied: protobuf!=4.0.*,!=4.21.*,!=4.22.0,!=4.23.*,!=4.24.*,<6.0.0.dev0,>=3.20.3 in ./.local/lib/python3.10/site-packages (from apache-beam->object-detection==0.1) (3.20.3)\n",
            "Collecting objsize<0.8.0,>=0.6.1\n",
            "  Using cached objsize-0.7.1-py3-none-any.whl (11 kB)\n",
            "Collecting pydot<2,>=1.2.0\n",
            "  Using cached pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
            "Collecting crcmod<2.0,>=1.7\n",
            "  Using cached crcmod-1.7-cp310-cp310-linux_x86_64.whl\n",
            "Collecting proto-plus<2,>=1.7.1\n",
            "  Using cached proto_plus-1.26.0-py3-none-any.whl (50 kB)\n",
            "Collecting pyarrow<17.0.0,>=3.0.0\n",
            "  Using cached pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.8 MB)\n",
            "Collecting opencv-python>=4.1.0.25\n",
            "  Using cached opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
            "Collecting kiwisolver>=1.1.0\n",
            "  Using cached kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
            "Collecting cycler>=0.10.0\n",
            "  Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Collecting contourpy>=1.0.1\n",
            "  Using cached contourpy-1.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (324 kB)\n",
            "Collecting fonttools>=4.22.0\n",
            "  Using cached fonttools-4.55.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.37.1 in ./.local/lib/python3.10/site-packages (from tensorflow_io->object-detection==0.1) (0.37.1)\n",
            "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5\n",
            "  Using cached google_api_core-2.24.1-py3-none-any.whl (160 kB)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in ./.local/lib/python3.10/site-packages (from google-api-python-client>=1.6.7->tf-models-official==2.15.0->object-detection==0.1) (2.38.0)\n",
            "Collecting uritemplate<5,>=3.0.1\n",
            "  Using cached uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
            "Collecting google-auth-httplib2<1.0.0,>=0.2.0\n",
            "  Using cached google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
            "Collecting docopt\n",
            "  Using cached docopt-0.6.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./.local/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object-detection==0.1) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in ./.local/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object-detection==0.1) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in ./.local/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object-detection==0.1) (0.22.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in ./.local/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object-detection==0.1) (25.1.0)\n",
            "Collecting certifi>=2023.7.22\n",
            "  Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
            "Collecting python-slugify\n",
            "  Using cached python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: urllib3 in /usr/lib/python3/dist-packages (from kaggle>=1.3.9->tf-models-official==2.15.0->object-detection==0.1) (1.26.5)\n",
            "Requirement already satisfied: bleach in ./.local/lib/python3.10/site-packages (from kaggle>=1.3.9->tf-models-official==2.15.0->object-detection==0.1) (6.2.0)\n",
            "Collecting tqdm\n",
            "  Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Collecting dnspython<3.0.0,>=1.16.0\n",
            "  Using cached dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "Collecting async-timeout>=4.0.3\n",
            "  Using cached async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.3)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in ./.local/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (2.15.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in ./.local/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in ./.local/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in ./.local/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (18.1.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in ./.local/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (2.15.0)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in ./.local/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (25.1.24)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in ./.local/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./.local/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in ./.local/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in ./.local/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (2.5.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in ./.local/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (3.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (59.6.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in ./.local/lib/python3.10/site-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (1.14.1)\n",
            "Collecting tf-keras>=2.14.1\n",
            "  Using cached tf_keras-2.18.0-py3-none-any.whl (1.7 MB)\n",
            "Collecting absl-py>=0.2.2\n",
            "  Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
            "Collecting dm-tree~=0.1.1\n",
            "  Using cached dm_tree-0.1.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (152 kB)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in ./.local/lib/python3.10/site-packages (from oauth2client->tf-models-official==2.15.0->object-detection==0.1) (0.4.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in ./.local/lib/python3.10/site-packages (from oauth2client->tf-models-official==2.15.0->object-detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: rsa>=3.1.4 in ./.local/lib/python3.10/site-packages (from oauth2client->tf-models-official==2.15.0->object-detection==0.1) (4.9)\n",
            "Collecting scikit-learn>=0.21.3\n",
            "  Using cached scikit_learn-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
            "Collecting etils[edc,enp,epath,epy,etree]>=1.6.0\n",
            "  Using cached etils-1.11.0-py3-none-any.whl (165 kB)\n",
            "Requirement already satisfied: click in /usr/lib/python3/dist-packages (from tensorflow-datasets->tf-models-official==2.15.0->object-detection==0.1) (8.0.3)\n",
            "Collecting promise\n",
            "  Using cached promise-2.3-py3-none-any.whl\n",
            "Collecting simple-parsing\n",
            "  Using cached simple_parsing-0.1.7-py3-none-any.whl (112 kB)\n",
            "Collecting tensorflow-metadata\n",
            "  Using cached tensorflow_metadata-1.16.1-py3-none-any.whl (28 kB)\n",
            "Collecting array-record>=0.5.0\n",
            "  Using cached array_record-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "Collecting toml\n",
            "  Using cached toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (0.37.1)\n",
            "Requirement already satisfied: zipp in /usr/lib/python3/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0->tensorflow-datasets->tf-models-official==2.15.0->object-detection==0.1) (1.0.0)\n",
            "Collecting fsspec\n",
            "  Using cached fsspec-2025.2.0-py3-none-any.whl (184 kB)\n",
            "Collecting importlib_resources\n",
            "  Using cached importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
            "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2\n",
            "  Using cached googleapis_common_protos-1.66.0-py2.py3-none-any.whl (221 kB)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./.local/lib/python3.10/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=1.6.7->tf-models-official==2.15.0->object-detection==0.1) (5.5.1)\n",
            "Collecting joblib>=1.2.0\n",
            "  Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "Collecting threadpoolctl>=3.1.0\n",
            "  Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in ./.local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (3.7)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in ./.local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (1.2.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./.local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in ./.local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (3.1.3)\n",
            "Collecting tf-keras>=2.14.1\n",
            "  Using cached tf_keras-2.17.0-py3-none-any.whl (1.7 MB)\n",
            "  Using cached tf_keras-2.16.0-py3-none-any.whl (1.7 MB)\n",
            "  Using cached tf_keras-2.15.1-py3-none-any.whl (1.7 MB)\n",
            "Requirement already satisfied: webencodings in ./.local/lib/python3.10/site-packages (from bleach->kaggle>=1.3.9->tf-models-official==2.15.0->object-detection==0.1) (0.5.1)\n",
            "Collecting text-unidecode>=1.3\n",
            "  Using cached text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
            "Collecting docstring-parser<1.0,>=0.15\n",
            "  Using cached docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./.local/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (2.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in ./.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (3.0.2)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official==2.15.0->object-detection==0.1) (3.2.0)\n",
            "Building wheels for collected packages: object-detection\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1697752 sha256=08d7cf2f3b401fd3be8ac046758f484678023a100b1f6537db58cdcfd595d369\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-dn7_g0ym/wheels/d2/91/19/8fcd2d3d66b31c32d80d2d33f433eeb698c65e1c289e384aa1\n",
            "Successfully built object-detection\n",
            "Installing collected packages: text-unidecode, sortedcontainers, sentencepiece, py-cpuinfo, gin-config, docopt, crcmod, zstandard, uritemplate, tzdata, tqdm, toml, threadpoolctl, tensorflow_io, tabulate, scipy, regex, pyyaml, python-slugify, pydot, pyarrow-hotfix, pyarrow, proto-plus, promise, portalocker, orjson, opencv-python-headless, opencv-python, objsize, lxml, kiwisolver, jsonpickle, joblib, importlib_resources, immutabledict, grpcio, googleapis-common-protos, fsspec, fonttools, fasteners, fastavro, etils, docstring-parser, dnspython, dill, Cython, cycler, contourpy, contextlib2, cloudpickle, certifi, avro-python3, async-timeout, absl-py, tf-slim, tensorflow-metadata, simple-parsing, scikit-learn, sacrebleu, redis, pymongo, pandas, oauth2client, matplotlib, dm-tree, tensorflow-model-optimization, seqeval, pycocotools, lvis, kaggle, hdfs, google-auth-httplib2, google-api-core, google-api-python-client, array-record, apache-beam, tensorflow-datasets, tf-keras, tensorflow-hub, tensorflow-text, tf-models-official, object-detection\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.70.0\n",
            "    Uninstalling grpcio-1.70.0:\n",
            "      Successfully uninstalled grpcio-1.70.0\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 2.1.0\n",
            "    Uninstalling absl-py-2.1.0:\n",
            "      Successfully uninstalled absl-py-2.1.0\n",
            "Successfully installed Cython-3.0.11 absl-py-1.4.0 apache-beam-2.62.0 array-record-0.6.0 async-timeout-5.0.1 avro-python3-1.10.2 certifi-2025.1.31 cloudpickle-2.2.1 contextlib2-21.6.0 contourpy-1.3.1 crcmod-1.7 cycler-0.12.1 dill-0.3.1.1 dm-tree-0.1.9 dnspython-2.7.0 docopt-0.6.2 docstring-parser-0.16 etils-1.11.0 fastavro-1.10.0 fasteners-0.19 fonttools-4.55.8 fsspec-2025.2.0 gin-config-0.5.0 google-api-core-2.24.1 google-api-python-client-2.160.0 google-auth-httplib2-0.2.0 googleapis-common-protos-1.66.0 grpcio-1.65.5 hdfs-2.7.3 immutabledict-4.2.1 importlib_resources-6.5.2 joblib-1.4.2 jsonpickle-3.4.2 kaggle-1.6.17 kiwisolver-1.4.8 lvis-0.5.3 lxml-5.3.0 matplotlib-3.10.0 oauth2client-4.1.3 object-detection-0.1 objsize-0.7.1 opencv-python-4.11.0.86 opencv-python-headless-4.11.0.86 orjson-3.10.15 pandas-2.2.3 portalocker-3.1.1 promise-2.3 proto-plus-1.26.0 py-cpuinfo-9.0.0 pyarrow-16.1.0 pyarrow-hotfix-0.6 pycocotools-2.0.8 pydot-1.4.2 pymongo-4.11 python-slugify-8.0.4 pyyaml-6.0.2 redis-5.2.1 regex-2024.11.6 sacrebleu-2.2.0 scikit-learn-1.6.1 scipy-1.15.1 sentencepiece-0.2.0 seqeval-1.2.2 simple-parsing-0.1.7 sortedcontainers-2.4.0 tabulate-0.9.0 tensorflow-datasets-4.9.7 tensorflow-hub-0.16.1 tensorflow-metadata-1.16.1 tensorflow-model-optimization-0.8.0 tensorflow-text-2.15.0 tensorflow_io-0.37.1 text-unidecode-1.3 tf-keras-2.15.1 tf-models-official-2.15.0 tf-slim-1.1.0 threadpoolctl-3.5.0 toml-0.10.2 tqdm-4.67.1 tzdata-2025.1 uritemplate-4.1.1 zstandard-0.23.0\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: tensorflow==2.15.0 in ./.local/lib/python3.10/site-packages (2.15.0)\n",
            "Requirement already satisfied: packaging in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (24.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (1.6.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (1.65.5)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (2.15.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (3.12.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (3.4.0)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (25.1.24)\n",
            "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow==2.15.0) (59.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (1.14.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow==2.15.0) (1.16.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (2.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (2.5.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (0.37.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (3.20.3)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (0.6.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (1.26.4)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in ./.local/lib/python3.10/site-packages (from tensorflow==2.15.0) (1.4.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow==2.15.0) (0.37.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in ./.local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in ./.local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.7)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in ./.local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.38.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in ./.local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.1.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./.local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.7.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in ./.local/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.32.3)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in ./.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.4.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (5.5.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./.local/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2025.1.31)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.26.5)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.4.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in ./.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in ./.local/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.2.0)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: protobuf==3.20.3 in ./.local/lib/python3.10/site-packages (3.20.3)\n"
          ]
        }
      ],
      "source": [
        "# Install\n",
        "!pip install {HOMEFOLDER}models/research/\n",
        "if(MLENVIRONMENT == \"COLAB\"):\n",
        "    !pip install tensorflow==2.15.0\n",
        "    !pip install protobuf==3.20.3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6V7TrfUos-9E"
      },
      "source": [
        "Test the environment by running `model_builder_tf2_test.py` to make sure everything is working as expected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wh_HPMOqWH9z",
        "outputId": "7f09ecf3-690a-4d2c-ab7c-293ec3b94a59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-02-06 21:16:19.508142: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
            "2025-02-06 21:16:19.508177: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
            "2025-02-06 21:16:19.509223: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
            "2025-02-06 21:16:19.513808: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\r\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-02-06 21:16:20.097548: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2025-02-06 21:16:21.933564: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_COMPAT_NOT_SUPPORTED_ON_DEVICE: forward compatibility was attempted on non supported HW\n",
            "2025-02-06 21:16:21.933592: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:129] retrieving CUDA diagnostic information for host: atharv-System-Product-Name\n",
            "2025-02-06 21:16:21.933598: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:136] hostname: atharv-System-Product-Name\n",
            "2025-02-06 21:16:21.933674: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:159] libcuda reported version is: 550.144.3\n",
            "2025-02-06 21:16:21.933692: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:163] kernel reported version is: 550.120.0\n",
            "2025-02-06 21:16:21.933697: E external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:244] kernel version 550.120.0 does not match DSO version 550.144.3 -- cannot find working devices in this configuration\n",
            "Running tests under Python 3.10.12: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "WARNING:tensorflow:`tf.keras.layers.experimental.SyncBatchNormalization` endpoint is deprecated and will be removed in a future release. Please use `tf.keras.layers.BatchNormalization` with parameter `synchronized` set to True.\n",
            "W0206 21:16:21.952792 124646020268032 batch_normalization.py:1531] `tf.keras.layers.experimental.SyncBatchNormalization` endpoint is deprecated and will be removed in a future release. Please use `tf.keras.layers.BatchNormalization` with parameter `synchronized` set to True.\n",
            "/home/atharv/.local/lib/python3.10/site-packages/object_detection/builders/model_builder.py:1112: DeprecationWarning: The 'warn' function is deprecated, use 'warning' instead\n",
            "  logging.warn(('Building experimental DeepMAC meta-arch.'\n",
            "W0206 21:16:22.213141 124646020268032 model_builder.py:1112] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 0.44s\n",
            "I0206 21:16:22.375445 124646020268032 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 0.44s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.33s\n",
            "I0206 21:16:22.706599 124646020268032 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.33s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.17s\n",
            "I0206 21:16:22.879353 124646020268032 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.17s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.15s\n",
            "I0206 21:16:23.034662 124646020268032 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.15s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.24s\n",
            "I0206 21:16:24.275383 124646020268032 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.24s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I0206 21:16:24.284989 124646020268032 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
            "I0206 21:16:24.300548 124646020268032 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
            "I0206 21:16:24.310441 124646020268032 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n",
            "I0206 21:16:24.320358 124646020268032 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.06s\n",
            "I0206 21:16:24.378270 124646020268032 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.06s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.06s\n",
            "I0206 21:16:24.433588 124646020268032 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.06s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.06s\n",
            "I0206 21:16:24.490711 124646020268032 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.06s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.06s\n",
            "I0206 21:16:24.548251 124646020268032 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.06s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.06s\n",
            "I0206 21:16:24.603736 124646020268032 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.06s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.02s\n",
            "I0206 21:16:24.620835 124646020268032 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I0206 21:16:24.721017 124646020268032 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I0206 21:16:24.721114 124646020268032 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 64\n",
            "I0206 21:16:24.721148 124646020268032 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 3\n",
            "I0206 21:16:24.722511 124646020268032 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0206 21:16:24.737493 124646020268032 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0206 21:16:24.737560 124646020268032 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0206 21:16:24.779886 124646020268032 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0206 21:16:24.779971 124646020268032 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0206 21:16:24.888584 124646020268032 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0206 21:16:24.888677 124646020268032 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0206 21:16:24.996645 124646020268032 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0206 21:16:24.996744 124646020268032 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0206 21:16:25.160428 124646020268032 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0206 21:16:25.160525 124646020268032 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0206 21:16:25.320847 124646020268032 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0206 21:16:25.320942 124646020268032 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0206 21:16:25.536038 124646020268032 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0206 21:16:25.536133 124646020268032 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I0206 21:16:25.589869 124646020268032 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I0206 21:16:25.617773 124646020268032 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0206 21:16:25.649656 124646020268032 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I0206 21:16:25.649745 124646020268032 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 88\n",
            "I0206 21:16:25.649779 124646020268032 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 4\n",
            "I0206 21:16:25.650912 124646020268032 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0206 21:16:25.660715 124646020268032 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0206 21:16:25.660764 124646020268032 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0206 21:16:25.740589 124646020268032 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0206 21:16:25.740676 124646020268032 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0206 21:16:25.882930 124646020268032 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0206 21:16:25.883035 124646020268032 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0206 21:16:26.027076 124646020268032 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I0206 21:16:26.027176 124646020268032 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0206 21:16:26.375108 124646020268032 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I0206 21:16:26.375203 124646020268032 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0206 21:16:26.575926 124646020268032 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I0206 21:16:26.576034 124646020268032 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0206 21:16:26.817949 124646020268032 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I0206 21:16:26.818053 124646020268032 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I0206 21:16:26.921561 124646020268032 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I0206 21:16:26.941351 124646020268032 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0206 21:16:26.977070 124646020268032 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I0206 21:16:26.977163 124646020268032 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 112\n",
            "I0206 21:16:26.977194 124646020268032 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 5\n",
            "I0206 21:16:26.978239 124646020268032 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0206 21:16:26.987835 124646020268032 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I0206 21:16:26.987888 124646020268032 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0206 21:16:27.058695 124646020268032 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I0206 21:16:27.058789 124646020268032 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0206 21:16:27.191213 124646020268032 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I0206 21:16:27.191312 124646020268032 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0206 21:16:27.347353 124646020268032 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0206 21:16:27.347459 124646020268032 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I0206 21:16:27.570710 124646020268032 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I0206 21:16:27.570814 124646020268032 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I0206 21:16:27.787764 124646020268032 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I0206 21:16:27.787862 124646020268032 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I0206 21:16:28.070083 124646020268032 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I0206 21:16:28.070183 124646020268032 efficientnet_model.py:143] round_filter input=320 output=352\n",
            "I0206 21:16:28.184938 124646020268032 efficientnet_model.py:143] round_filter input=1280 output=1408\n",
            "I0206 21:16:28.209624 124646020268032 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0206 21:16:28.245852 124646020268032 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I0206 21:16:28.245946 124646020268032 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 160\n",
            "I0206 21:16:28.245985 124646020268032 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 6\n",
            "I0206 21:16:28.247056 124646020268032 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I0206 21:16:28.259062 124646020268032 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I0206 21:16:28.259109 124646020268032 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0206 21:16:28.342539 124646020268032 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0206 21:16:28.342633 124646020268032 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0206 21:16:28.498221 124646020268032 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0206 21:16:28.498322 124646020268032 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0206 21:16:28.655242 124646020268032 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I0206 21:16:28.655338 124646020268032 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I0206 21:16:28.912292 124646020268032 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I0206 21:16:28.912395 124646020268032 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I0206 21:16:29.184188 124646020268032 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I0206 21:16:29.184287 124646020268032 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I0206 21:16:29.513202 124646020268032 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I0206 21:16:29.513305 124646020268032 efficientnet_model.py:143] round_filter input=320 output=384\n",
            "I0206 21:16:29.634307 124646020268032 efficientnet_model.py:143] round_filter input=1280 output=1536\n",
            "I0206 21:16:29.659715 124646020268032 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0206 21:16:29.698290 124646020268032 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I0206 21:16:29.698382 124646020268032 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 224\n",
            "I0206 21:16:29.698412 124646020268032 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 7\n",
            "I0206 21:16:29.699473 124646020268032 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0206 21:16:29.711472 124646020268032 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0206 21:16:29.711526 124646020268032 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0206 21:16:29.787330 124646020268032 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0206 21:16:29.787421 124646020268032 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0206 21:16:29.973334 124646020268032 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I0206 21:16:29.973437 124646020268032 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I0206 21:16:30.375111 124646020268032 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I0206 21:16:30.375212 124646020268032 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I0206 21:16:30.717636 124646020268032 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I0206 21:16:30.717744 124646020268032 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I0206 21:16:31.050169 124646020268032 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I0206 21:16:31.050265 124646020268032 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I0206 21:16:31.491286 124646020268032 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I0206 21:16:31.491387 124646020268032 efficientnet_model.py:143] round_filter input=320 output=448\n",
            "I0206 21:16:31.613393 124646020268032 efficientnet_model.py:143] round_filter input=1280 output=1792\n",
            "I0206 21:16:31.640710 124646020268032 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0206 21:16:31.685771 124646020268032 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I0206 21:16:31.685873 124646020268032 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 288\n",
            "I0206 21:16:31.685906 124646020268032 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 7\n",
            "I0206 21:16:31.686973 124646020268032 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0206 21:16:31.696480 124646020268032 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I0206 21:16:31.696530 124646020268032 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0206 21:16:31.807667 124646020268032 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I0206 21:16:31.807762 124646020268032 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0206 21:16:32.063836 124646020268032 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0206 21:16:32.063936 124646020268032 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I0206 21:16:32.324975 124646020268032 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I0206 21:16:32.325078 124646020268032 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I0206 21:16:32.701290 124646020268032 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I0206 21:16:32.701388 124646020268032 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I0206 21:16:33.098383 124646020268032 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I0206 21:16:33.098484 124646020268032 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I0206 21:16:33.614315 124646020268032 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I0206 21:16:33.614425 124646020268032 efficientnet_model.py:143] round_filter input=320 output=512\n",
            "I0206 21:16:33.807449 124646020268032 efficientnet_model.py:143] round_filter input=1280 output=2048\n",
            "I0206 21:16:33.836540 124646020268032 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0206 21:16:33.888997 124646020268032 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I0206 21:16:33.889097 124646020268032 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 384\n",
            "I0206 21:16:33.889131 124646020268032 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 8\n",
            "I0206 21:16:33.890238 124646020268032 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I0206 21:16:33.902995 124646020268032 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I0206 21:16:33.903076 124646020268032 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0206 21:16:34.035827 124646020268032 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0206 21:16:34.035935 124646020268032 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0206 21:16:34.333888 124646020268032 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I0206 21:16:34.333988 124646020268032 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I0206 21:16:34.649556 124646020268032 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I0206 21:16:34.649658 124646020268032 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I0206 21:16:35.358863 124646020268032 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I0206 21:16:35.358987 124646020268032 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I0206 21:16:35.880779 124646020268032 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I0206 21:16:35.880882 124646020268032 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I0206 21:16:36.595382 124646020268032 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I0206 21:16:36.595493 124646020268032 efficientnet_model.py:143] round_filter input=320 output=576\n",
            "I0206 21:16:36.822219 124646020268032 efficientnet_model.py:143] round_filter input=1280 output=2304\n",
            "I0206 21:16:36.858182 124646020268032 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0206 21:16:36.923487 124646020268032 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I0206 21:16:36.923589 124646020268032 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 384\n",
            "I0206 21:16:36.923619 124646020268032 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 8\n",
            "I0206 21:16:36.924764 124646020268032 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I0206 21:16:36.937174 124646020268032 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I0206 21:16:36.937282 124646020268032 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0206 21:16:37.105969 124646020268032 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I0206 21:16:37.106084 124646020268032 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I0206 21:16:37.504318 124646020268032 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I0206 21:16:37.504416 124646020268032 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I0206 21:16:37.864054 124646020268032 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I0206 21:16:37.864151 124646020268032 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I0206 21:16:38.396404 124646020268032 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I0206 21:16:38.396516 124646020268032 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I0206 21:16:39.389059 124646020268032 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I0206 21:16:39.389248 124646020268032 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I0206 21:16:40.727760 124646020268032 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I0206 21:16:40.727885 124646020268032 efficientnet_model.py:143] round_filter input=320 output=640\n",
            "I0206 21:16:41.202662 124646020268032 efficientnet_model.py:143] round_filter input=1280 output=2560\n",
            "I0206 21:16:41.257266 124646020268032 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 17.18s\n",
            "I0206 21:16:41.803966 124646020268032 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 17.18s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.01s\n",
            "I0206 21:16:41.996380 124646020268032 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.01s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I0206 21:16:41.997835 124646020268032 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I0206 21:16:41.998125 124646020268032 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I0206 21:16:41.998906 124646020268032 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I0206 21:16:41.999606 124646020268032 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I0206 21:16:41.999798 124646020268032 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I0206 21:16:42.000397 124646020268032 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 24 tests in 20.065s\n",
            "\n",
            "OK (skipped=1)\n"
          ]
        }
      ],
      "source": [
        "!python3 {HOMEFOLDER}models/research/object_detection/builders/model_builder_tf2_test.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmROIG9zaS9G"
      },
      "source": [
        "# 1.1. Get Dataset From Google Drive\n",
        "\n",
        "1. Expand this section\n",
        "2. Upload your RoboFlow .tfrecord.zip to Google Drive\n",
        "3. Share the uploaded .tfrecord.zip such that anyone with the link can access the file.\n",
        "4. Run this block\n",
        "5. Paste your Google Drive file share link into the text box that appears after running this block\n",
        "6. Click the \"Process Dataset\" Buttton\n",
        "7. Click the Refresh button in the \"Files\" pane to ensure dataset.zip exists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLgAPsQsfTLs"
      },
      "outputs": [],
      "source": [
        "import gdown\n",
        "import os\n",
        "from IPython.display import display\n",
        "from ipywidgets import Text, Button, VBox\n",
        "\n",
        "def process_dataset():\n",
        "    link_input = Text(\n",
        "        value='',\n",
        "        placeholder='Paste your Google Drive share link here',\n",
        "        description='Drive Link:',\n",
        "        style={'description_width': 'initial'},\n",
        "        layout={'width': '50%'}\n",
        "    )\n",
        "\n",
        "    def on_click(b):\n",
        "        try:\n",
        "            print(\"Downloading dataset...\")\n",
        "            url = link_input.value\n",
        "\n",
        "            # Convert share URL to direct download URL if needed\n",
        "            if 'drive.google.com/file/d/' in url:\n",
        "                file_id = url.split('/file/d/')[1].split('/')[0]\n",
        "                url = f'https://drive.google.com/uc?id={file_id}'\n",
        "\n",
        "            output = '/content/dataset.zip'\n",
        "            gdown.download(url, output, fuzzy=True)\n",
        "            print(\"Download complete!\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {str(e)}\")\n",
        "\n",
        "    process_button = Button(description='Process Dataset', button_style='primary')\n",
        "    process_button.on_click(on_click)\n",
        "    display(VBox([link_input, process_button]))\n",
        "\n",
        "# Install gdown if not already installed\n",
        "!pip install -q gdown --upgrade\n",
        "\n",
        "# Execute\n",
        "process_dataset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6kMXxVJo5za"
      },
      "source": [
        "# 2. Auto-detect relevant tfrecord components"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "WoA8HHf3I2t1",
        "outputId": "17186f93-877b-41c5-aa8c-ccc0d8d21ed8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/home/atharv/dataset.zip\n",
            "Archive:  /home/atharv/dataset.zip\r\n",
            "  inflating: README.dataset.txt      \r\n",
            "  inflating: README.roboflow.txt     \r\n",
            "   creating: test/\r\n",
            " extracting: test/coral-and-algae.tfrecord  \r\n",
            "  inflating: test/coral-and-algae_label_map.pbtxt  \r\n",
            "   creating: train/\n",
            " extracting: train/coral-and-algae.tfrecord  \n",
            "  inflating: train/coral-and-algae_label_map.pbtxt  \n",
            "   creating: valid/\n",
            " extracting: valid/coral-and-algae.tfrecord  \n",
            "  inflating: valid/coral-and-algae_label_map.pbtxt  \n"
          ]
        }
      ],
      "source": [
        "datasetPath = '/home/atharv/dataset.zip'\n",
        "print(datasetPath)\n",
        "!unzip $datasetPath"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "YUd2wtfrqedy",
        "outputId": "1866b977-137d-4377-8b67-f9f8b553c1b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Record File: /home/atharv/.local/share/Trash/files/train/coral-and-algae.tfrecord\n",
            "Validation Record File: /home/atharv/.local/share/Trash/files/valid/coral-and-algae.tfrecord\n",
            "Label Map File: /home/atharv/models/research/object_detection/data/fgvc_2854_classes_label_map.pbtxt\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import fnmatch\n",
        "\n",
        "def find_files(directory, pattern):\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for basename in files:\n",
        "            if fnmatch.fnmatch(basename, pattern):\n",
        "                filename = os.path.join(root, basename)\n",
        "                yield filename\n",
        "\n",
        "def set_tfrecord_variables(directory):\n",
        "    train_record_fname = ''\n",
        "    val_record_fname = ''\n",
        "    label_map_pbtxt_fname = ''\n",
        "\n",
        "    for tfrecord_file in find_files(directory, '*.tfrecord'):\n",
        "        if '/train/' in tfrecord_file:\n",
        "            train_record_fname = tfrecord_file\n",
        "        elif '/valid/' in tfrecord_file:\n",
        "            val_record_fname = tfrecord_file\n",
        "        elif '/test/' in tfrecord_file:\n",
        "            pass\n",
        "\n",
        "    for label_map_file in find_files(directory, '*_label_map.pbtxt'):\n",
        "        label_map_pbtxt_fname = label_map_file  # Assuming one common label map file\n",
        "\n",
        "    return train_record_fname, val_record_fname, label_map_pbtxt_fname\n",
        "\n",
        "\n",
        "train_record_fname, val_record_fname, label_map_pbtxt_fname = set_tfrecord_variables('/home/atharv')\n",
        "\n",
        "#if(MLENVIRONMENT==\"COLAB\"):\n",
        "    #train_record_fname = '/content/train/cubes-cones.tfrecord'\n",
        "    #val_record_fname = '/content/valid/cubes-cones.tfrecord'\n",
        "    #label_map_pbtxt_fname = '/content/train/cubes-cones_label_map.pbtxt'\n",
        "\n",
        "print(\"Train Record File:\", train_record_fname)\n",
        "print(\"Validation Record File:\", val_record_fname)\n",
        "print(\"Label Map File:\", label_map_pbtxt_fname)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGEUZYAMEZ6f"
      },
      "source": [
        "# 3.&nbsp;Training Configuration and Labels File Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2MAcgJ53STW"
      },
      "source": [
        "Download the pre-trained Limelight Base Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "gN0EUEa3e5Un",
        "outputId": "5a71d254-3bd0-4c11-91e5-96f8785bd2a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/home/atharv\n",
            "/home/atharv/models/mymodel\n",
            "--2025-02-08 07:58:18--  https://downloads.limelightvision.io/models/limelight_ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz\n",
            "Resolving downloads.limelightvision.io (downloads.limelightvision.io)... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/atharv/.local/lib/python3.10/site-packages/IPython/core/magics/osm.py:393: UserWarning: This is now an optional IPython functionality, using bookmarks requires you to install the `pickleshare` library.\n",
            "  bkms = self.shell.db.get('bookmarks', {})\n",
            "/home/atharv/.local/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
            "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2600:9000:21da:e400:c:efbc:d340:93a1, 2600:9000:21da:be00:c:efbc:d340:93a1, 2600:9000:21da:9600:c:efbc:d340:93a1, ...\r\n",
            "Connecting to downloads.limelightvision.io (downloads.limelightvision.io)|2600:9000:21da:e400:c:efbc:d340:93a1|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 46042990 (44M) [application/x-gzip]\n",
            "Saving to: â€˜limelight_ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gzâ€™\n",
            "\n",
            "limelight_ssd_mobil 100%[===================>]  43.91M  8.47MB/s    in 6.9s    \n",
            "\n",
            "2025-02-08 07:58:25 (6.39 MB/s) - â€˜limelight_ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gzâ€™ saved [46042990/46042990]\n",
            "\n",
            "--2025-02-08 07:58:26--  https://downloads.limelightvision.io/models/limelight_ssd_mobilenet_v2_320x320_coco17_tpu-8.config\n",
            "Resolving downloads.limelightvision.io (downloads.limelightvision.io)... 2600:9000:21da:8e00:c:efbc:d340:93a1, 2600:9000:21da:a000:c:efbc:d340:93a1, 2600:9000:21da:f600:c:efbc:d340:93a1, ...\n",
            "Connecting to downloads.limelightvision.io (downloads.limelightvision.io)|2600:9000:21da:8e00:c:efbc:d340:93a1|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4681 (4.6K) [binary/octet-stream]\n",
            "Saving to: â€˜limelight_ssd_mobilenet_v2_320x320_coco17_tpu-8.configâ€™\n",
            "\n",
            "limelight_ssd_mobil 100%[===================>]   4.57K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-02-08 07:58:26 (236 MB/s) - â€˜limelight_ssd_mobilenet_v2_320x320_coco17_tpu-8.configâ€™ saved [4681/4681]\n",
            "\n",
            "/home/atharv\n"
          ]
        }
      ],
      "source": [
        "chosen_model = 'ssd-mobilenet-v2'\n",
        "MODELS_CONFIG = {\n",
        "    'ssd-mobilenet-v2': {\n",
        "        'model_name': 'ssd_mobilenet_v2_320x320_coco17_tpu-8',\n",
        "        'base_pipeline_file': 'limelight_ssd_mobilenet_v2_320x320_coco17_tpu-8.config',\n",
        "        'pretrained_checkpoint': 'limelight_ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz',\n",
        "    },\n",
        "}\n",
        "model_name = MODELS_CONFIG[chosen_model]['model_name']\n",
        "pretrained_checkpoint = MODELS_CONFIG[chosen_model]['pretrained_checkpoint']\n",
        "base_pipeline_file = MODELS_CONFIG[chosen_model]['base_pipeline_file']\n",
        "\n",
        "# Create \"mymodel\" folder for pre-trained weights and configuration files\n",
        "%cd ~\n",
        "%mkdir {HOMEFOLDER}models/mymodel/\n",
        "%cd {HOMEFOLDER}models/mymodel/\n",
        "%pwd\n",
        "\n",
        "# Download pre-trained model weights\n",
        "import tarfile\n",
        "download_tar = 'https://downloads.limelightvision.io/models/' + pretrained_checkpoint\n",
        "!wget {download_tar}\n",
        "tar = tarfile.open(pretrained_checkpoint)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "# Download training configuration file for model\n",
        "download_config = 'https://downloads.limelightvision.io/models/' + base_pipeline_file\n",
        "!wget {download_config}\n",
        "%cd ~\n",
        "\n",
        "# Set training parameters for the model\n",
        "num_steps = 40000\n",
        "checkpoint_every = 2000\n",
        "batch_size = 16\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMbr89qqgTVW"
      },
      "source": [
        "Generate Labels File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "DDyH_i3MgP1D",
        "outputId": "14225808-ccd2-47a6-e6d7-849dcdbc59cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-02-08 07:58:30.097433: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-02-08 07:58:30.097488: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-02-08 07:58:30.114788: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-08 07:58:30.154525: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-02-08 07:58:30.922854: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total classes: 90\n",
            "['Nicrophorus tomentosus', 'Halyomorpha halys', 'Aramus guarauna', 'Rupornis magnirostris', 'Hyla eximia', 'Nannothemis bella', 'Acalymma vittatum', 'Ramphotyphlops braminus', 'Cyanocitta cristata', 'Drymarchon melanurus', 'Aenetus virescens', 'Cyanocitta stelleri', 'Polygrammate hebraeicum', 'Balearica regulorum', 'Fistularia commersonii', 'Syritta pipiens', 'Plestiodon fasciatus', 'Plestiodon inexpectatus', 'Pyrocephalus rubinus', 'Plestiodon laticeps', 'Anguilla rostrata', 'Plestiodon obsoletus', 'Plestiodon tetragrammus', 'Syntomoides imaon', 'Arion ater', 'Chamaeleo dilepis', 'Tragelaphus scriptus', 'Taeniopoda eques', 'Libellula quadrimaculata', 'Recurvirostra americana', 'Phalaenophana pyramusalis', 'Agalychnis dacnicolor', 'Haemulon sciurus', 'Cordulegaster diastatops', 'Ladona julia', 'Ardeotis kori', 'Diodon holocanthus', 'Papilio canadensis', 'Monochamus scutellatus', 'Ceratotherium simum simum', 'Cordulia shurtleffii', 'Pica nuttalli', 'Dasyprocta punctata', 'Perisoreus canadensis', 'Antigone canadensis', 'Aetobatus narinari', 'Phyciodes pulchella', 'Parkesia noveboracensis', 'Ardea herodias occidentalis', 'Pantherophis emoryi', 'Nehalennia irene', 'Pantherophis guttatus', 'Pantherophis obsoletus', 'Porzana carolina', 'Siproeta stelenes biplagiata', 'Physalia physalis', 'Bombus terrestris', 'Anas platyrhynchos diazi', 'Hyles lineata', 'Dolomedes tenebrosus', 'Varanus salvator', 'Epilachna mexicana', 'Desmodus rotundus', 'Motacilla cinerea', 'Papio ursinus', 'Empidonax difficilis', 'Empidonax minimus', 'Empidonax fulvifrons', 'Trite planiceps', 'Hemileuca eglanterina', 'Empidonax traillii', 'Ceratomia undulosa', 'Bittacomorpha clavipes', 'Xanthorhoe lacustrata', 'Empidonax hammondii', 'Empidonax occidentalis', 'Rallus limicola', 'Grus grus', 'Abudefduf saxatilis', 'Callophrys niphon', 'Zopherus nodulosus haldemani', 'Hermetia illucens', 'Quiscalus major', 'Branta leucopsis', 'Cyanocorax yucatanicus', 'Zamenis longissimus', 'Cyanocorax yncas', 'Nadata gibbosa', 'Ensatina eschscholtzii xanthoptica', 'Heterocampa biundata']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Set file locations and get number of classes for config file\n",
        "pipeline_fname = HOMEFOLDER+'models/mymodel/' + base_pipeline_file\n",
        "fine_tune_checkpoint = HOMEFOLDER+'models/mymodel/' + model_name + '/checkpoint/ckpt-0'\n",
        "\n",
        "def get_num_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=90, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "    return len(category_index.keys())\n",
        "\n",
        "def get_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=90, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "\n",
        "    class_names = [category['name'] for category in category_index.values()]\n",
        "    return class_names\n",
        "\n",
        "def create_label_file(filename, labels):\n",
        "    with open(filename, 'w') as file:\n",
        "        for label in labels:\n",
        "            file.write(label + '\\n')\n",
        "\n",
        "\n",
        "num_classes = get_num_classes(label_map_pbtxt_fname)\n",
        "classes = get_classes(label_map_pbtxt_fname)\n",
        "\n",
        "print('Total classes:', num_classes)\n",
        "print(classes)\n",
        "\n",
        "\n",
        "#Generate labels file\n",
        "create_label_file(HOMEFOLDER + \"limelight_neural_detector_labels.txt\", classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwPyaIAXxyKu"
      },
      "source": [
        "Modify the base Limelight Model Configuration File\n",
        "\n",
        "Augmentation Options: https://github.com/tensorflow/models/blob/master/research/object_detection/protos/preprocessor.proto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5eA5ht3_yukT"
      },
      "outputs": [],
      "source": [
        "# Create custom configuration file by writing the dataset, model checkpoint, and training parameters into the base pipeline file\n",
        "import re\n",
        "\n",
        "print('writing custom configuration file')\n",
        "\n",
        "\n",
        "\n",
        "with open(pipeline_fname) as f:\n",
        "    s = f.read()\n",
        "with open('pipeline_file.config', 'w') as f:\n",
        "\n",
        "    # Set fine_tune_checkpoint path\n",
        "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
        "\n",
        "    # Set tfrecord files for train and test datasets\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', 'input_path: \"{}\"'.format(val_record_fname), s)\n",
        "\n",
        "    # Set label_map_path\n",
        "    s = re.sub(\n",
        "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
        "\n",
        "    # Set batch_size\n",
        "    s = re.sub('batch_size: [0-9]+',\n",
        "               'batch_size: {}'.format(batch_size), s)\n",
        "\n",
        "    # Set training steps, num_steps\n",
        "    s = re.sub('num_steps: [0-9]+',\n",
        "               'num_steps: {}'.format(num_steps), s)\n",
        "\n",
        "    # Set number of classes num_classes\n",
        "    s = re.sub('checkpoint_every_n: [0-9]+',\n",
        "               'num_classes: {}'.format(num_classes), s)\n",
        "\n",
        "    # Change fine-tune checkpoint type from \"classification\" to \"detection\"\n",
        "    s = re.sub(\n",
        "        'fine_tune_checkpoint_type: \"classification\"', 'fine_tune_checkpoint_type: \"{}\"'.format('detection'), s)\n",
        "\n",
        "    # If using ssd-mobilenet-v2, reduce learning rate\n",
        "    if chosen_model == 'ssd-mobilenet-v2':\n",
        "      s = re.sub('learning_rate_base: .8',\n",
        "                 'learning_rate_base: .004', s)\n",
        "\n",
        "      s = re.sub('warmup_learning_rate: 0.13333',\n",
        "                 'warmup_learning_rate: .0016666', s)\n",
        "\n",
        "    # If using efficientdet-d0, use fixed_shape_resizer instead of keep_aspect_ratio_resizer (because it isn't supported by TFLite)\n",
        "    if chosen_model == 'efficientdet-d0':\n",
        "      s = re.sub('keep_aspect_ratio_resizer', 'fixed_shape_resizer', s)\n",
        "      s = re.sub('pad_to_max_dimension: true', '', s)\n",
        "      s = re.sub('min_dimension', 'height', s)\n",
        "      s = re.sub('max_dimension', 'width', s)\n",
        "\n",
        "    f.write(s)\n",
        "\n",
        "# (Optional) Display the custom configuration file's contents\n",
        "# !cat pipeline_file.config\n",
        "# Set the path to the custom config file and the directory to store training checkpoints in\n",
        "pipeline_file = 'pipeline_file.config'\n",
        "model_dir = HOMEFOLDER+'training_progress/'\n",
        "print(\" \")\n",
        "print(model_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-19zML6oEO7l"
      },
      "source": [
        "# 4.&nbsp;Train Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxPj_QV43qD5"
      },
      "source": [
        "Once training starts, come back and click the refresh button within the tensorboard window to check training progress.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TI9iCCxoNlAL"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir '/content/training_progress/train'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejo07C1zXHzY"
      },
      "source": [
        "Fix TF 2.15 breaking changes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ltvi224axv3Y"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "import re\n",
        "\n",
        "original_path = '/usr/local/lib/python3.11/dist-packages/tf_slim/data/tfexample_decoder.py'\n",
        "with open(original_path, 'r') as file:\n",
        "  content = file.read()\n",
        "  content = re.sub(r'import abc', 'import tensorflow as tf\\n\\nimport abc', content)\n",
        "  content = re.sub(r'control_flow_ops.case', 'tf.case', content)\n",
        "  content = re.sub(r'control_flow_ops.cond', 'tf.compat.v1.cond', content)\n",
        "with open(original_path, 'w') as file:\n",
        "  file.write(content)\n",
        "\n",
        "print(f\"File {original_path} fixed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjqYo9r9ffVx"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQTfZChVzzpZ"
      },
      "outputs": [],
      "source": [
        "!rm -rf {HOMEFOLDER}training_progress\n",
        "# Run training!\n",
        "!python {HOMEFOLDER}models/research/object_detection/model_main_tf2.py \\\n",
        "    --pipeline_config_path={pipeline_file} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\\n",
        "    --checkpoint_every_n={checkpoint_every} \\\n",
        "    --num_train_steps={num_steps} \\\n",
        "    --num_workers=2 \\\n",
        "    --sample_1_of_n_eval_examples=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHxbX4ZpzXIv"
      },
      "source": [
        "Feel free to stop training early. Check the 'training_progress' folder to see all training checkpoints.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPg8oMnQDYKl"
      },
      "source": [
        "# 5.&nbsp;Convert Model to TFLite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RaUU8tBlHifd"
      },
      "outputs": [],
      "source": [
        "#remove final output folder if it exists\n",
        "if os.path.exists(FINALOUTPUTFOLDER) and os.path.isdir(FINALOUTPUTFOLDER):\n",
        "  shutil.rmtree(FINALOUTPUTFOLDER)\n",
        "\n",
        "# Make a directory to store the trained TFLite model\n",
        "!mkdir {FINALOUTPUTFOLDER}\n",
        "print(FINALOUTPUTFOLDER)\n",
        "# Export graph\n",
        "# Path to training directory (the conversion script automatically chooses the highest checkpoint file)\n",
        "last_model_path = HOMEFOLDER+'training_progress'\n",
        "exporter_path = HOMEFOLDER+'models/research/object_detection/export_tflite_graph_tf2.py'\n",
        "output_directory = FINALOUTPUTFOLDER\n",
        "\n",
        "!python $exporter_path \\\n",
        "    --trained_checkpoint_dir $last_model_path \\\n",
        "    --output_directory $output_directory \\\n",
        "    --pipeline_config_path $pipeline_file\n",
        "\n",
        "# Convert to .tflite Flatbuffer\n",
        "import tensorflow as tf\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(FINALOUTPUTFOLDER+'/saved_model')\n",
        "tflite_model = converter.convert()\n",
        "model_path_32bit = FINALOUTPUTFOLDER+'/limelight_neural_detector_32bit.tflite'\n",
        "with open(model_path_32bit, 'wb') as f:\n",
        "  f.write(tflite_model)\n",
        "\n",
        "!cp {HOMEFOLDER}limelight_neural_detector_labels.txt {FINALOUTPUTFOLDER}\n",
        "!cp {HOMEFOLDER}models/mymodel/pipeline_file.config {FINALOUTPUTFOLDER}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqahbHU1suBi"
      },
      "outputs": [],
      "source": [
        "# Export graph\n",
        "# Path to training directory (the conversion script automatically chooses the highest checkpoint file)\n",
        "last_model_path = HOMEFOLDER+'training_progress'\n",
        "exporter_path = HOMEFOLDER+'models/research/object_detection/export_tflite_graph_tf2.py'\n",
        "output_directory = FINALOUTPUTFOLDER\n",
        "\n",
        "!python $exporter_path \\\n",
        "    --trained_checkpoint_dir $last_model_path \\\n",
        "    --output_directory $output_directory \\\n",
        "    --pipeline_config_path $pipeline_file\n",
        "\n",
        "# Convert to .tflite Flatbuffer\n",
        "import tensorflow as tf\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(FINALOUTPUTFOLDER+'/saved_model')\n",
        "tflite_model = converter.convert()\n",
        "model_path_32bit = FINALOUTPUTFOLDER+'/limelight_neural_detector_32bit.tflite'\n",
        "with open(model_path_32bit, 'wb') as f:\n",
        "  f.write(tflite_model)\n",
        "\n",
        "!cp {HOMEFOLDER}limelight_neural_detector_labels.txt {FINALOUTPUTFOLDER}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTyqlXFTJ0Uv"
      },
      "source": [
        "# 6. Quantize model\n",
        "The \"TFLiteConverter\" module will perform [post-training quantization](https://www.tensorflow.org/lite/performance/post_training_quantization) on the model. To quantize the model, we need to provide a set of example images. We will extract 100 images from the training tfrecord and place said images into the \"extracted_samples\" folder.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSNZtfj_k3NP"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import io\n",
        "from PIL import Image\n",
        "\n",
        "def extract_images_from_tfrecord(tfrecord_path, output_folder, num_samples=100):\n",
        "    # Make sure the output directory exists\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Initialize a counter for the number of images saved\n",
        "    saved_images = 0\n",
        "\n",
        "    # Read the TFRecord file\n",
        "    raw_dataset = tf.data.TFRecordDataset(tfrecord_path)\n",
        "    for raw_record in raw_dataset.take(num_samples):\n",
        "        example = tf.train.Example()\n",
        "        example.ParseFromString(raw_record.numpy())\n",
        "\n",
        "        # Extract the image data (change 'image/encoded' if necessary)\n",
        "        image_data = example.features.feature['image/encoded'].bytes_list.value[0]\n",
        "\n",
        "        # Decode the image data and save as a file\n",
        "        image = Image.open(io.BytesIO(image_data))\n",
        "        image.save(os.path.join(output_folder, f'image_{saved_images}.png'))\n",
        "\n",
        "        saved_images += 1\n",
        "        if saved_images >= num_samples:\n",
        "            break\n",
        "\n",
        "    print(f\"Extracted {saved_images} images to {output_folder}\")\n",
        "\n",
        "# Set the path to your TFRecord file and the output directory\n",
        "tfrecord_path = train_record_fname\n",
        "extracted_sample_folder = HOMEFOLDER+'extracted_samples'\n",
        "\n",
        "#remove sample folder if it exists\n",
        "if os.path.exists(extracted_sample_folder) and os.path.isdir(extracted_sample_folder):\n",
        "  shutil.rmtree(extracted_sample_folder)\n",
        "\n",
        "# Extract images\n",
        "extract_images_from_tfrecord(tfrecord_path, extracted_sample_folder)\n",
        "\n",
        "\n",
        "# Get list of all images in train directory\n",
        "from google.cloud import storage\n",
        "import glob\n",
        "\n",
        "quant_image_list=[]\n",
        "if(MLENVIRONMENT==\"COLAB\"):\n",
        "\n",
        "    jpg_file_list = glob.glob(extracted_sample_folder + '/*.jpg')\n",
        "    jpeg_file_list = glob.glob(extracted_sample_folder + '/*.jpeg')\n",
        "    JPG_file_list = glob.glob(extracted_sample_folder + '/*.JPG')\n",
        "    png_file_list = glob.glob(extracted_sample_folder + '/*.png')\n",
        "    bmp_file_list = glob.glob(extracted_sample_folder + '/*.bmp')\n",
        "    quant_image_list = jpg_file_list + JPG_file_list + png_file_list + bmp_file_list\n",
        "\n",
        "print(\"pulling samples from \" + extracted_sample_folder)\n",
        "print(\"samples: \" + str(len(quant_image_list)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORzx0XRErSLV"
      },
      "outputs": [],
      "source": [
        "# A generator that provides a representative dataset\n",
        "# Code modified from https://colab.research.google.com/github/google-coral/tutorials/blob/master/retrain_classification_ptq_tf2.ipynb\n",
        "\n",
        "# First, get input details for model so we know how to preprocess images\n",
        "interpreter = tf.lite.Interpreter(model_path=model_path_32bit)\n",
        "interpreter.allocate_tensors()\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "height = input_details[0]['shape'][1]\n",
        "width = input_details[0]['shape'][2]\n",
        "\n",
        "import random\n",
        "\n",
        "def representative_data_gen():\n",
        "  dataset_list = quant_image_list\n",
        "  quant_num = 300\n",
        "  for i in range(quant_num):\n",
        "    pick_me = random.choice(dataset_list)\n",
        "    print(pick_me)\n",
        "    image = tf.io.read_file(pick_me)\n",
        "\n",
        "    if pick_me.endswith('.jpg') or pick_me.endswith('.JPG') or pick_me.endswith('.jpeg'):\n",
        "      image = tf.io.decode_jpeg(image, channels=3)\n",
        "    elif pick_me.endswith('.png'):\n",
        "      image = tf.io.decode_png(image, channels=3)\n",
        "    elif pick_me.endswith('.bmp'):\n",
        "      image = tf.io.decode_bmp(image, channels=3)\n",
        "\n",
        "    image = tf.image.resize(image, [width, height])  # TO DO: Replace 300s with an automatic way of reading network input size\n",
        "    image = tf.cast(image / 255., tf.float32)\n",
        "    image = tf.expand_dims(image, 0)\n",
        "    yield [image]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqtu98mzebEj"
      },
      "source": [
        "Finally, we'll initialize the TFLiteConverter module, point it at the TFLite graph we generated in Step 6, and provide it with the representative dataset generator function we created in the previous code block. We'll configure the converter to quantize the model's weight values to INT8 format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ox0bGDWds_Ce"
      },
      "outputs": [],
      "source": [
        "# Initialize converter module\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(FINALOUTPUTFOLDER+'/saved_model')\n",
        "print(\"initialized converter\")\n",
        "# This enables quantization\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "# This sets the representative dataset for quantization\n",
        "converter.representative_dataset = representative_data_gen\n",
        "# This ensures that if any ops can't be quantized, the converter throws an error\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "# For full integer quantization, though supported types defaults to int8 only, we explicitly declare it for clarity.\n",
        "converter.target_spec.supported_types = [tf.int8]\n",
        "# These set the input tensors to uint8 and output tensors to float32\n",
        "converter.inference_input_type = tf.uint8\n",
        "converter.inference_output_type = tf.float32\n",
        "print(\"begin conversion\")\n",
        "tflite_model = converter.convert()\n",
        "print(\"conversion complete\")\n",
        "\n",
        "with open(FINALOUTPUTFOLDER+'/limelight_neural_detector_8bit.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFsuasvxFHo8"
      },
      "source": [
        "# 7. Compile Model for Limelight & Download\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peawOI_z0DHt"
      },
      "source": [
        "Install Coral Compiler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUd_SNC0JSq0"
      },
      "outputs": [],
      "source": [
        "! curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n",
        "! echo \"deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\" | sudo tee /etc/apt/sources.list.d/coral-edgetpu.list\n",
        "! sudo apt-get update\n",
        "! sudo apt-get install edgetpu-compiler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usfmdtSiJuuC"
      },
      "source": [
        "Compile the previously-generated 8-bit model for Google Coral"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mULCY0nb0ahH"
      },
      "outputs": [],
      "source": [
        "!cd {FINALOUTPUTFOLDER} && pwd && edgetpu_compiler limelight_neural_detector_8bit.tflite && pwd && mv limelight_neural_detector_8bit_edgetpu.tflite limelight_neural_detector_coral.tflite && rm limelight_neural_detector_8bit_edgetpu.log"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqGy2FgzKomN"
      },
      "source": [
        "Zip models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nCdUouYJjQM"
      },
      "outputs": [],
      "source": [
        "!rm {HOMEFOLDER}limelight_detectors.zip\n",
        "!zip -r {HOMEFOLDER}limelight_detectors.zip {FINALOUTPUTFOLDER}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHgbpkQue-ZR"
      },
      "source": [
        "Download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AmjqvKuuK8ZR"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download(HOMEFOLDER+'limelight_detectors.zip')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "05N8FeXHcQp3",
        "xmROIG9zaS9G",
        "eGEUZYAMEZ6f",
        "-19zML6oEO7l",
        "kPg8oMnQDYKl",
        "VTyqlXFTJ0Uv",
        "XFsuasvxFHo8"
      ],
      "gpuClass": "premium",
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "dac6b1a68a930bf8a24417228a96ab80b19f2aa97bc2d428affc356154b4740f"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}